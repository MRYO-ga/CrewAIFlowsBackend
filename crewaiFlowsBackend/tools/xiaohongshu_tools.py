from typing import List, Dict, Any, Optional, Type
from datetime import datetime, timedelta
from crewai.tools import BaseTool
from pydantic import BaseModel, Field
import random
import json
import os

# è¾“å…¥å‚æ•°æ¨¡å‹å®šä¹‰
class XiaoHongShuSearchInput(BaseModel):
    """å°çº¢ä¹¦æœç´¢è¾“å…¥å‚æ•°"""
    query: str = Field(..., description="æœç´¢å…³é”®è¯")
    num: int = Field(default=10, description="éœ€è¦è¿”å›çš„ç»“æœæ•°é‡")
    note_type: int = Field(default=0, description="ç¬”è®°ç±»å‹ï¼Œ0:å…¨éƒ¨, 1:è§†é¢‘, 2:å›¾æ–‡")

class XiaoHongShuPublishInput(BaseModel):
    """å°çº¢ä¹¦å‘å¸ƒè¾“å…¥å‚æ•°"""
    title: str = Field(..., description="ç¬”è®°æ ‡é¢˜")
    content: str = Field(..., description="ç¬”è®°å†…å®¹")
    images: List[str] = Field(default=[], description="å›¾ç‰‡URLåˆ—è¡¨")
    tags: List[str] = Field(default=[], description="æ ‡ç­¾åˆ—è¡¨")

class XiaoHongShuAccountInput(BaseModel):
    """å°çº¢ä¹¦è´¦å·è¾“å…¥å‚æ•°"""
    account_id: str = Field(..., description="è´¦å·ID")

class XiaoHongShuComplianceInput(BaseModel):
    """å°çº¢ä¹¦åˆè§„æ£€æŸ¥è¾“å…¥å‚æ•°"""
    content: str = Field(..., description="å¾…æ£€æŸ¥çš„å†…å®¹")

# è·å–ç”¨æˆ·ä¿¡æ¯å·¥å…·è¾“å…¥æ¨¡å‹
class UserInfoInput(BaseModel):
    """è·å–ç”¨æˆ·ä¿¡æ¯å·¥å…·çš„è¾“å…¥å‚æ•°"""
    account_id: str = Field(..., description="å°çº¢ä¹¦è´¦å·ID")

# è·å–å…³é”®è¯è”æƒ³è¯å·¥å…·è¾“å…¥æ¨¡å‹
class SearchKeywordInput(BaseModel):
    """è·å–å…³é”®è¯è”æƒ³è¯å·¥å…·çš„è¾“å…¥å‚æ•°"""
    keyword: str = Field(..., description="æ ¸å¿ƒå…³é”®è¯")

# æœç´¢ç”¨æˆ·å·¥å…·è¾“å…¥æ¨¡å‹
class SearchUserInput(BaseModel):
    """æœç´¢ç”¨æˆ·å·¥å…·çš„è¾“å…¥å‚æ•°"""
    keyword: str = Field(..., description="æœç´¢å…³é”®è¯")
    limit: int = Field(default=20, description="è¿”å›ç»“æœé™åˆ¶æ•°é‡")

# è·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°å·¥å…·è¾“å…¥æ¨¡å‹
class UserAllNotesInput(BaseModel):
    """è·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°å·¥å…·çš„è¾“å…¥å‚æ•°"""
    user_id: str = Field(..., description="ç”¨æˆ·ID")
    limit: int = Field(default=50, description="è¿”å›ç»“æœé™åˆ¶æ•°é‡")

# è·å–é¦–é¡µæ¨èå†…å®¹å·¥å…·è¾“å…¥æ¨¡å‹
class HomefeedRecommendInput(BaseModel):
    """è·å–é¦–é¡µæ¨èå†…å®¹å·¥å…·çš„è¾“å…¥å‚æ•°"""
    category: str = Field(..., description="å†…å®¹å“ç±»ï¼Œå¦‚'æŠ¤è‚¤'ã€'å¥èº«'ç­‰")
    num: int = Field(default=50, description="è¿”å›ç»“æœæ•°é‡")

# æœç´¢ç¬”è®°å·¥å…·è¾“å…¥æ¨¡å‹
class SearchNoteInput(BaseModel):
    """æœç´¢ç¬”è®°å·¥å…·çš„è¾“å…¥å‚æ•°"""
    keyword: str = Field(..., description="æœç´¢å…³é”®è¯")
    days: int = Field(default=30, description="é™å®šå¤©æ•°èŒƒå›´")
    min_likes: int = Field(default=0, description="æœ€å°ç‚¹èµæ•°")
    sort_by: str = Field(default="hot", description="æ’åºæ–¹å¼ï¼Œhotæˆ–time")

# è·å–ç¬”è®°è¯¦æƒ…å·¥å…·è¾“å…¥æ¨¡å‹
class NoteInfoInput(BaseModel):
    """è·å–ç¬”è®°è¯¦æƒ…å·¥å…·çš„è¾“å…¥å‚æ•°"""
    note_id: str = Field(..., description="ç¬”è®°ID")

# è·å–æ— æ°´å°è§†é¢‘å·¥å…·è¾“å…¥æ¨¡å‹
class NoWaterVideoInput(BaseModel):
    """è·å–æ— æ°´å°è§†é¢‘å·¥å…·çš„è¾“å…¥å‚æ•°"""
    note_id: str = Field(..., description="ç¬”è®°ID")

class XiaoHongShuContentTool(BaseTool):
    """å°çº¢ä¹¦å†…å®¹å·¥å…·"""
    name: str = "xiaohongshu_content_tool"
    description: str = "ç”¨äºæœç´¢ã€åˆ†æå’Œç”Ÿæˆå°çº¢ä¹¦å†…å®¹çš„å·¥å…·ã€‚å¯ä»¥æœç´¢ç¬”è®°ã€åˆ†æå†…å®¹ç‰¹ç‚¹ç­‰ã€‚"
    args_schema: Type[BaseModel] = XiaoHongShuSearchInput

    def _run(self, query: str, num: int = 10, note_type: int = 0) -> Dict[str, Any]:
        """æ‰§è¡Œå°çº¢ä¹¦å†…å®¹æœç´¢"""
        # å®é™…å®ç°ä¸­è°ƒç”¨å°çº¢ä¹¦API
        return {
            "success": True,
            "results": [
                {
                    "title": f"æœç´¢ç»“æœ{i+1}",
                    "content": f"å†…å®¹{i+1}",
                    "likes": 100 * (i+1)
                } for i in range(num)
            ]
        }

    async def _arun(self, query: str, num: int = 10, note_type: int = 0) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œå°çº¢ä¹¦å†…å®¹æœç´¢"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class XiaoHongShuPublicationTool(BaseTool):
    """å°çº¢ä¹¦å‘å¸ƒå·¥å…·"""
    name: str = "xiaohongshu_publication_tool"
    description: str = "ç”¨äºå‘å¸ƒå’Œç®¡ç†å°çº¢ä¹¦å†…å®¹çš„å·¥å…·ã€‚å¯ä»¥å‘å¸ƒç¬”è®°ã€è®¾ç½®å®šæ—¶å‘å¸ƒã€æ·»åŠ æ ‡ç­¾ç­‰ã€‚"
    args_schema: Type[BaseModel] = XiaoHongShuPublishInput

    def _run(self, title: str, content: str, images: List[str] = None, tags: List[str] = None) -> Dict[str, Any]:
        """å‘å¸ƒå°çº¢ä¹¦å†…å®¹"""
        # å®é™…å®ç°ä¸­è°ƒç”¨å°çº¢ä¹¦API
        return {
            "success": True,
            "publication_id": "pub_123456",
            "url": "https://xiaohongshu.com/note/123456"
        }

    async def _arun(self, title: str, content: str, images: List[str] = None, tags: List[str] = None) -> Dict[str, Any]:
        """å¼‚æ­¥å‘å¸ƒå°çº¢ä¹¦å†…å®¹"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class XiaoHongShuCompetitorTool(BaseTool):
    """å°çº¢ä¹¦ç«å“åˆ†æå·¥å…·"""
    name: str = "xiaohongshu_competitor_tool"
    description: str = "ç”¨äºåˆ†æç«å“è´¦å·å’Œå†…å®¹çš„å·¥å…·ã€‚å¯ä»¥åˆ†æç«å“è´¦å·æ•°æ®ã€çˆ†æ¬¾å†…å®¹ç‰¹ç‚¹ç­‰ã€‚"
    args_schema: Type[BaseModel] = XiaoHongShuAccountInput

    def _run(self, account_id: str) -> Dict[str, Any]:
        """åˆ†æç«å“è´¦å·"""
        # å®é™…å®ç°ä¸­è°ƒç”¨å°çº¢ä¹¦API
        return {
            "success": True,
            "account_info": {
                "followers": 10000,
                "posts": 100,
                "engagement_rate": 5.2
            }
        }

    async def _arun(self, account_id: str) -> Dict[str, Any]:
        """å¼‚æ­¥åˆ†æç«å“è´¦å·"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class XiaoHongShuAccountTool:
    """å°çº¢ä¹¦è´¦å·å·¥å…·ç±»ï¼Œæä¾›å°çº¢ä¹¦ç›¸å…³APIæ¥å£å°è£…"""
    
    def __init__(self):
        """åˆå§‹åŒ–å·¥å…·ç±»"""
        self.api_base = "https://api.xiaohongshu.com"
        
    def fetch_account_info(self, account_id: str) -> Dict[str, Any]:
        """
        è·å–è´¦å·åŸºæœ¬ä¿¡æ¯
        
        Args:
            account_id: å°çº¢ä¹¦è´¦å·ID
            
        Returns:
            Dict: è´¦å·åŸºæœ¬ä¿¡æ¯
        """
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        mock_data = {
            "id": account_id,
            "name": "æµ‹è¯•è´¦å·" if not account_id else f"å°çº¢ä¹¦è´¦å·_{account_id[:5]}",
            "followers": random.randint(1000, 50000),
            "following": random.randint(100, 500),
            "notes_count": random.randint(50, 200),
            "likes_count": random.randint(5000, 100000),
            "bio": "è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•è´¦å·çš„ç®€ä»‹ï¼Œä¸“æ³¨äºåˆ†äº«ä¼˜è´¨å†…å®¹",
        }
        
        return mock_data
        
    def update_account_persona(self, account_id: str, data: Dict[str, Any]) -> bool:
        """
        æ›´æ–°è´¦å·äººè®¾ä¿¡æ¯
        
        Args:
            account_id: å°çº¢ä¹¦è´¦å·ID
            data: è¦æ›´æ–°çš„æ•°æ®
            
        Returns:
            bool: æ›´æ–°æ˜¯å¦æˆåŠŸ
        """
        # æ¨¡æ‹ŸAPIè°ƒç”¨
        success = True
        print(f"æ›´æ–°è´¦å· {account_id} ä¿¡æ¯: {json.dumps(data, ensure_ascii=False)}")
        return success
    
    def get_user_info(self, account_id: str) -> Dict[str, Any]:
        """
        åˆ†æå¯¹æ ‡è´¦å·çš„åç§°/ç®€ä»‹ç»“æ„
        
        Args:
            account_id: å°çº¢ä¹¦è´¦å·ID
            
        Returns:
            Dict: è´¦å·è¯¦ç»†ä¿¡æ¯åˆ†æ
        """
        # æ¨¡æ‹ŸAPIè¿”å›çƒ­é—¨è´¦å·çš„åç§°ç»“æ„å’Œç®€ä»‹ç‰¹ç‚¹åˆ†æ
        account_types = [
            "ä¸“ä¸šå‹", "ç”Ÿæ´»æ–¹å¼å‹", "çŸ¥è¯†åˆ†äº«å‹", "ä¸ªæ€§åŒ–IPå‹", "å…´è¶£çˆ±å¥½å‹"
        ]
        
        name_structures = [
            "é¢†åŸŸ+èº«ä»½æ ‡è¯†ï¼ˆå¦‚ï¼šæŠ¤è‚¤å°è°¯è¨€ï¼‰",
            "äººç‰©ç‰¹å¾+ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚ï¼šåŠå…¬å®¤å¥èº«å°Cï¼‰",
            "åˆ›æ„æ˜µç§°+emojiï¼ˆå¦‚ï¼šè‚Œè‚¤å®ˆæŠ¤è€…ğŸ›¡ï¸ï¼‰",
            "æ•…äº‹åŒ–æ˜µç§°ï¼ˆå¦‚ï¼šæ·±å¤œå¥èº«æˆ¿ï¼‰",
            "ä¸“ä¸šåº¦+é¢†åŸŸï¼ˆå¦‚ï¼šè®¤è¯é¦™æ°´å¸ˆï¼‰"
        ]
        
        bio_features = [
            "æ•°æ®åŒ–æ‰¿è¯ºï¼ˆ8å¹´ç»éªŒ|100+äº§å“æµ‹è¯„ï¼‰",
            "ä¸“ä¸šèº«ä»½è®¤è¯ï¼ˆXXå¤§å­¦|XXè¯ä¹¦æŒæœ‰è€…ï¼‰",
            "å†…å®¹é¢„æœŸï¼ˆæ¯å‘¨Xæ›´æ–°|å¹²è´§åˆ†äº«ï¼‰",
            "ä¸ªæ€§åŒ–æ ‡è¯­ï¼ˆæ‹’ç»è™šå‡ç§è‰|åªåˆ†äº«çœŸå®ä½“éªŒï¼‰",
            "äº’åŠ¨å¼•å¯¼ï¼ˆå…³æ³¨æˆ‘äº†è§£æ›´å¤š|è¯„è®ºåŒºå‘Šè¯‰æˆ‘ä½ æƒ³çœ‹ä»€ä¹ˆï¼‰"
        ]
        
        account_type = random.choice(account_types)
        selected_name_structures = random.sample(name_structures, 2)
        selected_bio_features = random.sample(bio_features, 3)
        
        return {
            "account_id": account_id,
            "account_type": account_type,
            "name_structure_analysis": selected_name_structures,
            "bio_features": selected_bio_features,
            "recommendation": f"å»ºè®®é‡‡ç”¨{account_type}å®šä½ï¼Œä½¿ç”¨{selected_name_structures[0]}å‘½åç»“æ„ï¼Œç®€ä»‹ä¸­åŠ å…¥{selected_bio_features[0]}å…ƒç´ æå‡ä¸“ä¸šæ„Ÿ"
        }
    
    def get_search_keyword(self, keyword: str) -> Dict[str, Any]:
        """
        è·å–æœç´¢å…³é”®è¯çš„è”æƒ³è¯
        
        Args:
            keyword: æ ¸å¿ƒå…³é”®è¯
            
        Returns:
            Dict: å…³é”®è¯ç›¸å…³è”æƒ³è¯å’Œåˆ†æ
        """
        # æ¨¡æ‹ŸAPIè¿”å›å…³é”®è¯è”æƒ³åˆ†æ
        keyword_categories = {
            "æŠ¤è‚¤": ["æ•æ„Ÿè‚ŒæŠ¤è‚¤", "æ²¹çš®æŠ¤è‚¤", "æŠ—è€æŠ¤è‚¤", "ç¾ç™½æŠ¤è‚¤", "ä¿æ¹¿è¡¥æ°´"],
            "å¥èº«": ["å±…å®¶å¥èº«", "åŠå…¬å®¤å¥èº«", "å¢è‚Œå¥èº«", "å‡è„‚å¥èº«", "é€šå‹¤å¥èº«"],
            "ç¾é£Ÿ": ["å®¶å¸¸èœè°±", "å‡è„‚é¤", "ä¸‹åˆèŒ¶", "æ—©é¤é£Ÿè°±", "å¿«æ‰‹æ–™ç†"],
            "ç©¿æ­": ["æ—¥å¸¸ç©¿æ­", "èŒåœºç©¿æ­", "çº¦ä¼šç©¿æ­", "è½»å¥¢ç©¿æ­", "æ˜¾ç˜¦ç©¿æ­"]
        }
        
        # å†³å®šä½¿ç”¨å“ªä¸ªç±»åˆ«çš„å…³é”®è¯
        category = None
        for cat, keywords in keyword_categories.items():
            if keyword.lower() in cat.lower():
                category = cat
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„ç±»åˆ«ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«
        if not category:
            category = random.choice(list(keyword_categories.keys()))
        
        # è·å–ç›¸å…³è”æƒ³è¯
        related_keywords = keyword_categories[category]
        search_volume = [random.randint(1000, 50000) for _ in range(len(related_keywords))]
        
        # åˆ›å»ºæ’åºåçš„å…³é”®è¯å’Œæœç´¢é‡çš„åˆ—è¡¨
        keyword_data = list(zip(related_keywords, search_volume))
        keyword_data.sort(key=lambda x: x[1], reverse=True)
        
        top_keywords = [k for k, _ in keyword_data[:3]]
        
        return {
            "core_keyword": keyword,
            "related_keywords": related_keywords,
            "search_volume": dict(zip(related_keywords, search_volume)),
            "top_recommendations": top_keywords,
            "analysis": f"æœç´¢'{keyword}'çš„ç”¨æˆ·å¤šå…³æ³¨'{top_keywords[0]}'å’Œ'{top_keywords[1]}'ç›¸å…³å†…å®¹ï¼Œå»ºè®®åœ¨è´¦å·æ ‡ç­¾å’Œå†…å®¹ä¸­åŠ å…¥è¿™äº›å…³é”®è¯ä»¥æé«˜æ›å…‰"
        }
    
    def search_user(self, keyword: str, limit: int = 20) -> Dict[str, Any]:
        """
        æœç´¢åŒé¢†åŸŸè´¦å·
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœé™åˆ¶
            
        Returns:
            Dict: è´¦å·åˆ—è¡¨å’Œåˆ†æ
        """
        # æ¨¡æ‹ŸAPIè¿”å›æœç´¢ç»“æœ
        results = []
        persona_keywords = [
            "ä¸“ä¸š", "è¾¾äºº", "åšä¸»", "æ•™ç»ƒ", "è€å¸ˆ", "æµ‹è¯„å¸ˆ", "ç§è‰å®˜", "åˆ›ä½œè€…", 
            "ç”Ÿæ´»å®¶", "è®¾è®¡å¸ˆ", "ç©å®¶", "å¥èº«è¾¾äºº", "æ­é…å¸ˆ", "ç¾å¦†åšä¸»"
        ]
        
        for i in range(limit):
            persona_type = random.choice(persona_keywords)
            follower_count = random.randint(1000, 500000)
            
            results.append({
                "user_id": f"user_{i}_{keyword.replace(' ', '_')}",
                "nickname": f"{keyword}{persona_type}{i+1}å·",
                "follower_count": follower_count,
                "notes_count": random.randint(50, 300),
                "persona_keywords": random.sample(persona_keywords, 3),
                "description": f"ä¸“æ³¨äº{keyword}å†…å®¹åˆ†äº«" if i % 3 != 0 else f"{keyword}é¢†åŸŸåˆ›ä½œè€…ï¼Œæä¾›ä¸“ä¸š{keyword}æŒ‡å¯¼"
            })
        
        # æŒ‰ç²‰ä¸æ•°æ’åº
        results.sort(key=lambda x: x["follower_count"], reverse=True)
        
        # åˆ†æäººè®¾åŒè´¨åŒ–é—®é¢˜
        common_keywords = set()
        for result in results[:5]:  # åªåˆ†æå‰5ä¸ªè´¦å·
            common_keywords.update(result["persona_keywords"])
        
        return {
            "accounts": results,
            "analysis": {
                "total_found": len(results),
                "common_persona_keywords": list(common_keywords),
                "homogenization_issues": f"åœ¨{keyword}é¢†åŸŸå‰20åè´¦å·ä¸­ï¼Œ{round(len(results) * 0.7)}ä¸ªä½¿ç”¨ç±»ä¼¼äººè®¾å®šä½ï¼Œå»ºè®®é¿å…ä½¿ç”¨{list(common_keywords)[:3]}ç­‰é«˜é¢‘äººè®¾å…³é”®è¯ï¼Œå¯»æ‰¾å·®å¼‚åŒ–å®šä½"
            }
        }
    
    def get_user_all_notes(self, user_id: str, limit: int = 50) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›ç»“æœé™åˆ¶
            
        Returns:
            Dict: åŒ…å«ç¬”è®°åˆ—è¡¨å’Œåˆ†æ
        """
        # æ¨¡æ‹Ÿç¬”è®°ä¸»é¢˜
        topics = ["äº§å“æµ‹è¯„", "ä½¿ç”¨æ•™ç¨‹", "ç»éªŒåˆ†äº«", "é—®é¢˜è§£å†³", "æ–°å“æ¨è", "ç§‘æ™®çŸ¥è¯†", "è¶‹åŠ¿åˆ†æ"]
        
        # æ¨¡æ‹Ÿç¬”è®°æ ¼å¼
        formats = ["å›¾æ–‡æµ‹è¯„", "è§†é¢‘è®°å½•", "æ¸…å•æ€»ç»“", "é—®ç­”è§£æ", "æ­¥éª¤æ•™ç¨‹", "å¯¹æ¯”åˆ†æ"]
        
        # ç”Ÿæˆéšæœºç¬”è®°æ•°æ®
        notes = []
        for i in range(limit):
            topic = random.choice(topics)
            note_format = random.choice(formats)
            
            notes.append({
                "note_id": f"note_{i}_{user_id}",
                "title": f"{topic}ï¼š{note_format}{i+1}",
                "type": "å›¾æ–‡" if random.random() > 0.3 else "è§†é¢‘",
                "likes": random.randint(10, 5000),
                "comments": random.randint(0, 200),
                "collects": random.randint(5, 500),
                "create_time": f"2023-{random.randint(1, 12)}-{random.randint(1, 28)}",
                "topic": topic,
                "format": note_format
            })
        
        # åˆ†æä¸»é¢˜åˆ†å¸ƒ
        topic_distribution = {}
        for note in notes:
            topic = note["topic"]
            topic_distribution[topic] = topic_distribution.get(topic, 0) + 1
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        for topic in topic_distribution:
            topic_distribution[topic] = round(topic_distribution[topic] / len(notes) * 100)
        
        # åˆ†æé«˜é¢‘äººè®¾å…³é”®è¯
        format_distribution = {}
        for note in notes:
            format_name = note["format"]
            format_distribution[format_name] = format_distribution.get(format_name, 0) + 1
        
        return {
            "user_id": user_id,
            "notes_count": len(notes),
            "notes": notes,
            "analysis": {
                "topic_distribution": topic_distribution,
                "format_distribution": format_distribution,
                "top_performing_topics": [k for k, v in sorted(topic_distribution.items(), key=lambda item: item[1], reverse=True)][:3],
                "persona_keywords": ["ä¸“ä¸š", "å®ç”¨", "æ·±åº¦" if random.random() > 0.5 else "é€šä¿—æ˜“æ‡‚"],
                "content_focus": f"å†…å®¹{round(topic_distribution.get('äº§å“æµ‹è¯„', 0) + topic_distribution.get('ç»éªŒåˆ†äº«', 0))}%é›†ä¸­åœ¨äº§å“æµ‹è¯„å’Œç»éªŒåˆ†äº«ï¼Œå»ºè®®å¼€æ‹“æ›´å¤š{random.choice(list(set(topics) - {'äº§å“æµ‹è¯„', 'ç»éªŒåˆ†äº«'}))}ç±»å†…å®¹"
            }
        }
    
    def get_homefeed_recommend_by_num(self, category: str, num: int = 50) -> Dict[str, Any]:
        """
        è·å–é¦–é¡µæ¨èå†…å®¹
        
        Args:
            category: å†…å®¹å“ç±»
            num: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            Dict: æ¨èå†…å®¹åˆ—è¡¨å’Œåˆ†æ
        """
        # å†…å®¹å½¢å¼åˆ—è¡¨
        content_forms = [
            "é—®é¢˜-è§£å†³æ–¹æ¡ˆå›¾æ–‡", "æ­¥éª¤åˆ†è§£å›¾æ–‡", "å¯¹æ¯”å›¾æ–‡", "æ¸…å•å‹å›¾æ–‡", 
            "è·Ÿç»ƒè§†é¢‘", "Vlogè§†é¢‘", "æµ‹è¯„è§†é¢‘", "çŸ¥è¯†ç‚¹è®²è§£è§†é¢‘"
        ]
        
        # ç”Ÿæˆéšæœºæ¨èå†…å®¹
        recommendations = []
        for i in range(num):
            content_form = random.choice(content_forms)
            is_video = "è§†é¢‘" in content_form
            
            recommendations.append({
                "note_id": f"note_{i}_{category.replace(' ', '_')}",
                "title": f"{random.choice(['å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'è¿™æ ·åš', 'å¿…çœ‹'])}ï¼š{category}{content_form}å†…å®¹{i+1}",
                "type": "è§†é¢‘" if is_video else "å›¾æ–‡",
                "likes": random.randint(500, 50000),
                "comments": random.randint(10, 2000),
                "collects": random.randint(100, 10000),
                "create_time": f"2023-{random.randint(1, 12)}-{random.randint(1, 28)}",
                "content_form": content_form,
                "has_purchase": random.choice([True, False, False, False])  # 25%æ¦‚ç‡æœ‰è´­ç‰©é“¾æ¥
            })
        
        # æŒ‰äº’åŠ¨é‡æ’åº
        recommendations.sort(key=lambda x: x["likes"] + x["comments"]*3 + x["collects"]*2, reverse=True)
        
        # åˆ†æå†…å®¹å½¢å¼åˆ†å¸ƒ
        form_distribution = {}
        for rec in recommendations:
            form = rec["content_form"]
            form_distribution[form] = form_distribution.get(form, 0) + 1
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        for form in form_distribution:
            form_distribution[form] = round(form_distribution[form] / len(recommendations) * 100)
        
        # åˆ†æè§†é¢‘ä¸å›¾æ–‡æ¯”ä¾‹
        video_count = sum(1 for rec in recommendations if rec["type"] == "è§†é¢‘")
        video_percentage = round(video_count / len(recommendations) * 100)
        
        # åˆ†ææ ‡é¢˜ç‰¹å¾
        title_features = []
        if any("å¦‚ä½•" in rec["title"] for rec in recommendations[:10]):
            title_features.append("é—®é¢˜è§£å†³å‹")
        if any("å¿…çœ‹" in rec["title"] for rec in recommendations[:10]):
            title_features.append("å¼ºè°ƒé‡è¦æ€§")
        if any(str(n) in rec["title"] for n in range(1, 10) for rec in recommendations[:10]):
            title_features.append("æ•°å­—å¼•å¯¼å‹")
        
        return {
            "category": category,
            "total_recommendations": len(recommendations),
            "top_recommendations": recommendations[:10],
            "analysis": {
                "content_form_distribution": form_distribution,
                "video_percentage": video_percentage,
                "image_text_percentage": 100 - video_percentage,
                "title_features": title_features,
                "trending_forms": [k for k, v in sorted(form_distribution.items(), key=lambda item: item[1], reverse=True)][:3],
                "insight": f"åœ¨{category}å“ç±»ä¸­ï¼Œ{[k for k, v in sorted(form_distribution.items(), key=lambda item: item[1], reverse=True)][0]}æœ€å—æ¬¢è¿ï¼Œå æ¯”{form_distribution[[k for k, v in sorted(form_distribution.items(), key=lambda item: item[1], reverse=True)][0]]}%ï¼Œå»ºè®®ä¼˜å…ˆé‡‡ç”¨æ­¤å†…å®¹å½¢å¼"
            }
        }
    
    def search_note(self, keyword: str, days: int = 30, min_likes: int = 0, sort_by: str = "hot") -> Dict[str, Any]:
        """
        æœç´¢ç¬”è®°
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            days: é™å®šå¤©æ•°èŒƒå›´
            min_likes: æœ€å°ç‚¹èµæ•°
            sort_by: æ’åºæ–¹å¼ï¼Œhotæˆ–time
            
        Returns:
            Dict: ç¬”è®°åˆ—è¡¨å’Œåˆ†æ
        """
        # ç”Ÿæˆéšæœºæœç´¢ç»“æœ
        num_results = random.randint(30, 100)
        results = []
        
        # å¸¸è§æ ‡é¢˜ç»“æ„
        title_structures = [
            "æ•°å­—+ç—›ç‚¹+è§£å†³æ–¹æ¡ˆ",
            "ç–‘é—®å¥+ç­”æ¡ˆæš—ç¤º",
            "å¼ºè°ƒè¯+æ ¸å¿ƒåˆ©ç›Šç‚¹",
            "ç´§æ€¥æ„Ÿ+å…³é”®ç»“æœ",
            "å¯¹æ¯”å‹+è½¬æŠ˜"
        ]
        
        # å†…å®¹ç±»å‹
        content_types = ["æ•™ç¨‹", "åˆ†äº«", "æµ‹è¯„", "è®°å½•", "æ€»ç»“", "æ”»ç•¥"]
        
        # ç”Ÿæˆæœç´¢ç»“æœ
        for i in range(num_results):
            likes = random.randint(10, 20000)
            if likes < min_likes:
                likes = min_likes + random.randint(0, 1000)
                
            content_type = random.choice(content_types)
            title_structure = random.choice(title_structures)
            
            # æ ¹æ®æ ‡é¢˜ç»“æ„ç”Ÿæˆæ ‡é¢˜
            if "æ•°å­—" in title_structure:
                title = f"{random.randint(1, 10)}ä¸ª{keyword}{content_type}æ–¹æ³•"
            elif "ç–‘é—®å¥" in title_structure:
                title = f"å¦‚ä½•æŒæ¡{keyword}çš„{content_type}æŠ€å·§ï¼Ÿ"
            elif "å¼ºè°ƒè¯" in title_structure:
                title = f"å¿…å­¦ï¼{keyword}{content_type}ç»æŠ€"
            elif "ç´§æ€¥æ„Ÿ" in title_structure:
                title = f"é€Ÿæ”¶è—ï¼{keyword}é«˜æ•ˆ{content_type}"
            else:
                title = f"ä»¥å‰vsç°åœ¨ï¼š{keyword}{content_type}æ–°æ–¹æ³•"
            
            results.append({
                "note_id": f"note_search_{i}",
                "title": title,
                "type": "è§†é¢‘" if random.random() > 0.6 else "å›¾æ–‡",
                "likes": likes,
                "comments": random.randint(5, min(likes//2, 1000)),
                "collects": random.randint(10, min(likes//1.5, 2000)),
                "create_time": f"2023-{random.randint(1, 12)}-{random.randint(1, 28)}",
                "content_type": content_type,
                "title_structure": title_structure
            })
        
        # æŒ‰ç‚¹èµæ•°æ’åº
        if sort_by == "hot":
            results.sort(key=lambda x: x["likes"], reverse=True)
        else:
            # æŒ‰æ—¶é—´æ’åºï¼Œè¿™é‡Œç®€å•æ¨¡æ‹Ÿ
            random.shuffle(results)
        
        # ç­›é€‰æ»¡è¶³ç‚¹èµè¦æ±‚çš„ç¬”è®°
        filtered_results = [r for r in results if r["likes"] >= min_likes]
        
        # åˆ†æé«˜é¢‘é€‰é¢˜
        topic_count = {}
        for result in filtered_results:
            topic = result["content_type"]
            topic_count[topic] = topic_count.get(topic, 0) + 1
        
        # åˆ†ææ ‡é¢˜ç»“æ„
        structure_count = {}
        for result in filtered_results:
            structure = result["title_structure"]
            structure_count[structure] = structure_count.get(structure, 0) + 1
        
        return {
            "keyword": keyword,
            "days_range": days,
            "min_likes": min_likes,
            "total_results": len(filtered_results),
            "notes": filtered_results[:20],  # åªè¿”å›å‰20æ¡ç»“æœ
            "analysis": {
                "popular_topics": {k: round(v/len(filtered_results)*100) for k, v in sorted(topic_count.items(), key=lambda item: item[1], reverse=True)},
                "effective_title_structures": {k: round(v/len(filtered_results)*100) for k, v in sorted(structure_count.items(), key=lambda item: item[1], reverse=True)},
                "high_engagement_topics": [k for k, v in sorted(topic_count.items(), key=lambda item: item[1], reverse=True)][:3],
                "recommendation": f"å»ºè®®ä¼˜å…ˆåˆ›ä½œ{[k for k, v in sorted(topic_count.items(), key=lambda item: item[1], reverse=True)][0]}ç±»å‹å†…å®¹ï¼Œä½¿ç”¨{[k for k, v in sorted(structure_count.items(), key=lambda item: item[1], reverse=True)][0]}æ ‡é¢˜ç»“æ„ï¼Œå¯æ˜¾è‘—æé«˜å†…å®¹æ›å…‰åº¦"
            }
        }
        
    def get_note_info(self, note_id: str) -> Dict[str, Any]:
        """
        è·å–ç¬”è®°è¯¦æƒ…
        
        Args:
            note_id: ç¬”è®°ID
            
        Returns:
            Dict: ç¬”è®°è¯¦æƒ…
        """
        # æ¨¡æ‹Ÿç¬”è®°è¯¦æƒ…
        note_type = "è§†é¢‘" if random.random() > 0.6 else "å›¾æ–‡"
        likes = random.randint(500, 50000)
        
        # æ ‡é¢˜ç»“æ„ç±»å‹
        title_structures = {
            "æ•°å­—å¼•å¯¼å‹": f"{random.randint(1, 10)}ä¸ªå°æŠ€å·§è®©ä½ è½»æ¾æŒæ¡",
            "é—®é¢˜è§£å†³å‹": "å¦‚ä½•è§£å†³é•¿ä¹…å›°æ‰°çš„é—®é¢˜ï¼Ÿ",
            "åˆ©ç›Šæš—ç¤ºå‹": "å­¦ä¼šè¿™ä¸ªæŠ€å·§ï¼Œæ•ˆç‡æå‡300%",
            "ç´§æ€¥æ„Ÿå‹": "å¿…çœ‹ï¼è¿™äº›é”™è¯¯ä½ ä¸€å®šåœ¨çŠ¯",
            "å¯¹æ¯”è½¬æŠ˜å‹": "å¯¹æ¯”ï¼šä»å…¥é—¨åˆ°ç²¾é€šçš„èœ•å˜"
        }
        
        structure_type = random.choice(list(title_structures.keys()))
        title = title_structures[structure_type]
        
        # å†…å®¹ç»“æ„
        content_structure = {
            "å¼•è¨€": "ç‚¹æ˜ç—›ç‚¹ï¼Œå¼•å‘å…±é¸£",
            "ä¸»ä½“": "åˆ†æ­¥éª¤/åˆ†ç‚¹å±•ç¤ºæ ¸å¿ƒå†…å®¹",
            "ç»“å°¾": "æ€»ç»“è¦ç‚¹ï¼Œå¼•å¯¼äº’åŠ¨/å…³æ³¨"
        }
        
        # äº’åŠ¨æ•°æ®
        interaction_data = {
            "likes": likes,
            "comments": random.randint(10, min(likes//3, 2000)),
            "collects": random.randint(50, min(likes//2, 5000)),
            "shares": random.randint(5, min(likes//4, 1000))
        }
        
        # ç”¨æˆ·è¯„è®ºå…³é”®è¯
        comment_keywords = ["å®ç”¨", "å¹²è´§", "å­¦åˆ°äº†", "æ„Ÿè°¢åˆ†äº«", "æ”¶è—äº†"]
        
        return {
            "note_id": note_id,
            "title": title,
            "title_structure": structure_type,
            "type": note_type,
            "content_structure": content_structure,
            "interaction_data": interaction_data,
            "comment_keywords": random.sample(comment_keywords, 3),
            "analysis": {
                "engagement_rate": round((interaction_data["comments"] + interaction_data["shares"]) / interaction_data["likes"] * 100),
                "collection_rate": round(interaction_data["collects"] / interaction_data["likes"] * 100),
                "title_effectiveness": "é«˜" if interaction_data["likes"] > 5000 else "ä¸­",
                "recommended_improvement": f"å»ºè®®åœ¨{random.choice(['æ ‡é¢˜', 'å¼€å¤´', 'ç»“å°¾'])}å¢åŠ {random.choice(['ç”¨æˆ·å¼•å¯¼', 'æ•°æ®æ”¯æŒ', 'æƒ…æ„Ÿå…±é¸£'])}å…ƒç´ ï¼Œæå‡äº’åŠ¨ç‡"
            }
        }
    
    def get_note_no_water_video(self, note_id: str) -> Dict[str, Any]:
        """
        è·å–ç¬”è®°æ— æ°´å°è§†é¢‘é“¾æ¥
        
        Args:
            note_id: ç¬”è®°ID
            
        Returns:
            Dict: æ— æ°´å°è§†é¢‘ä¿¡æ¯
        """
        return {
            "note_id": note_id,
            "video_url": f"https://example.com/xhs/video/{note_id}.mp4",
            "duration": random.randint(15, 180),
            "resolution": random.choice(["1080p", "720p"]),
            "message": "è§†é¢‘é“¾æ¥å·²ç”Ÿæˆï¼Œä»…ä¾›å­¦ä¹ å‚è€ƒ"
        }

class XiaoHongShuComplianceTool(BaseTool):
    """å°çº¢ä¹¦åˆè§„æ£€æŸ¥å·¥å…·"""
    name: str = "xiaohongshu_compliance_tool"
    description: str = "ç”¨äºæ£€æŸ¥å†…å®¹åˆè§„æ€§å’Œæ•æ„Ÿè¯çš„å·¥å…·ã€‚å¯ä»¥æ£€æŸ¥å†…å®¹æ˜¯å¦è¿è§„ã€åŒ…å«æ•æ„Ÿè¯ç­‰ã€‚"
    args_schema: Type[BaseModel] = XiaoHongShuComplianceInput

    def _run(self, content: str) -> Dict[str, Any]:
        """æ£€æŸ¥å†…å®¹åˆè§„æ€§"""
        # å®é™…å®ç°ä¸­è°ƒç”¨åˆè§„æ£€æŸ¥API
        return {
            "success": True,
            "is_compliant": True,
            "issues": []
        }

    async def _arun(self, content: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ£€æŸ¥å†…å®¹åˆè§„æ€§"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

# å·¥å…·ç±»å®šä¹‰

class GetUserInfoTool(BaseTool):
    """åˆ†æå¯¹æ ‡è´¦å·çš„åç§°/ç®€ä»‹ç»“æ„å·¥å…·"""
    name: str = "get_user_info"
    description: str = "åˆ†æå¯¹æ ‡è´¦å·çš„åç§°ç»“æ„ä¸ç®€ä»‹ç‰¹ç‚¹ï¼Œå¦‚åˆ†æå¤´éƒ¨è´¦å·'åŠå…¬å®¤å¥èº«å°C'çš„åç§°æ„æˆ"
    args_schema: Type[BaseModel] = UserInfoInput

    def _run(self, account_id: str) -> Dict[str, Any]:
        """
        åˆ†æå¯¹æ ‡è´¦å·çš„åç§°/ç®€ä»‹ç»“æ„
        
        Args:
            account_id: å°çº¢ä¹¦è´¦å·ID
            
        Returns:
            Dict: è´¦å·è¯¦ç»†ä¿¡æ¯åˆ†æ
        """
        # æ¨¡æ‹ŸAPIè¿”å›çƒ­é—¨è´¦å·çš„åç§°ç»“æ„å’Œç®€ä»‹ç‰¹ç‚¹åˆ†æ
        account_types = [
            "ä¸“ä¸šå‹", "ç”Ÿæ´»æ–¹å¼å‹", "çŸ¥è¯†åˆ†äº«å‹", "ä¸ªæ€§åŒ–IPå‹", "å…´è¶£çˆ±å¥½å‹"
        ]
        
        name_structures = [
            "é¢†åŸŸ+èº«ä»½æ ‡è¯†ï¼ˆå¦‚ï¼šæŠ¤è‚¤å°è°¯è¨€ï¼‰",
            "äººç‰©ç‰¹å¾+ä¸“ä¸šé¢†åŸŸï¼ˆå¦‚ï¼šåŠå…¬å®¤å¥èº«å°Cï¼‰",
            "åˆ›æ„æ˜µç§°+emojiï¼ˆå¦‚ï¼šè‚Œè‚¤å®ˆæŠ¤è€…ğŸ›¡ï¸ï¼‰",
            "æ•…äº‹åŒ–æ˜µç§°ï¼ˆå¦‚ï¼šæ·±å¤œå¥èº«æˆ¿ï¼‰",
            "ä¸“ä¸šåº¦+é¢†åŸŸï¼ˆå¦‚ï¼šè®¤è¯é¦™æ°´å¸ˆï¼‰"
        ]
        
        bio_features = [
            "æ•°æ®åŒ–æ‰¿è¯ºï¼ˆ8å¹´ç»éªŒ|100+äº§å“æµ‹è¯„ï¼‰",
            "ä¸“ä¸šèº«ä»½è®¤è¯ï¼ˆXXå¤§å­¦|XXè¯ä¹¦æŒæœ‰è€…ï¼‰",
            "å†…å®¹é¢„æœŸï¼ˆæ¯å‘¨Xæ›´æ–°|å¹²è´§åˆ†äº«ï¼‰",
            "ä¸ªæ€§åŒ–æ ‡è¯­ï¼ˆæ‹’ç»è™šå‡ç§è‰|åªåˆ†äº«çœŸå®ä½“éªŒï¼‰",
            "äº’åŠ¨å¼•å¯¼ï¼ˆå…³æ³¨æˆ‘äº†è§£æ›´å¤š|è¯„è®ºåŒºå‘Šè¯‰æˆ‘ä½ æƒ³çœ‹ä»€ä¹ˆï¼‰"
        ]
        
        account_type = random.choice(account_types)
        selected_name_structures = random.sample(name_structures, 2)
        selected_bio_features = random.sample(bio_features, 3)
        
        return {
            "account_id": account_id,
            "account_type": account_type,
            "name_structure_analysis": selected_name_structures,
            "bio_features": selected_bio_features,
            "recommendation": f"å»ºè®®é‡‡ç”¨{account_type}å®šä½ï¼Œä½¿ç”¨{selected_name_structures[0]}å‘½åç»“æ„ï¼Œç®€ä»‹ä¸­åŠ å…¥{selected_bio_features[0]}å…ƒç´ æå‡ä¸“ä¸šæ„Ÿ"
        }
    
    async def _arun(self, account_id: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè·å–è´¦å·ä¿¡æ¯"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class GetSearchKeywordTool(BaseTool):
    """è·å–å…³é”®è¯è”æƒ³è¯å·¥å…·"""
    name: str = "get_search_keyword"
    description: str = "è·å–æ ¸å¿ƒå…³é”®è¯çš„ç›¸å…³è”æƒ³è¯ï¼Œå¦‚è·å–'èŒåœºå¥èº«'ç›¸å…³è”æƒ³è¯ï¼ˆ'é€šå‹¤æ‹‰ä¼¸'ã€'ä¹…åæŠ¤è…°'ç­‰ï¼‰ï¼Œä¼˜åŒ–è´¦å·æ ‡ç­¾ä½“ç³»"
    args_schema: Type[BaseModel] = SearchKeywordInput
    
    def _run(self, keyword: str) -> Dict[str, Any]:
        """
        è·å–æœç´¢å…³é”®è¯çš„è”æƒ³è¯
        
        Args:
            keyword: æ ¸å¿ƒå…³é”®è¯
            
        Returns:
            Dict: å…³é”®è¯ç›¸å…³è”æƒ³è¯å’Œåˆ†æ
        """
        # æ¨¡æ‹ŸAPIè¿”å›å…³é”®è¯è”æƒ³åˆ†æ
        keyword_categories = {
            "æŠ¤è‚¤": ["æ•æ„Ÿè‚ŒæŠ¤è‚¤", "æ²¹çš®æŠ¤è‚¤", "æŠ—è€æŠ¤è‚¤", "ç¾ç™½æŠ¤è‚¤", "ä¿æ¹¿è¡¥æ°´"],
            "å¥èº«": ["å±…å®¶å¥èº«", "åŠå…¬å®¤å¥èº«", "å¢è‚Œå¥èº«", "å‡è„‚å¥èº«", "é€šå‹¤å¥èº«"],
            "ç¾é£Ÿ": ["å®¶å¸¸èœè°±", "å‡è„‚é¤", "ä¸‹åˆèŒ¶", "æ—©é¤é£Ÿè°±", "å¿«æ‰‹æ–™ç†"],
            "ç©¿æ­": ["æ—¥å¸¸ç©¿æ­", "èŒåœºç©¿æ­", "çº¦ä¼šç©¿æ­", "è½»å¥¢ç©¿æ­", "æ˜¾ç˜¦ç©¿æ­"]
        }
        
        # å†³å®šä½¿ç”¨å“ªä¸ªç±»åˆ«çš„å…³é”®è¯
        category = None
        for cat, keywords in keyword_categories.items():
            if keyword.lower() in cat.lower():
                category = cat
                break
        
        # å¦‚æœæ‰¾ä¸åˆ°åŒ¹é…çš„ç±»åˆ«ï¼Œä½¿ç”¨é»˜è®¤ç±»åˆ«
        if not category:
            category = random.choice(list(keyword_categories.keys()))
        
        # è·å–ç›¸å…³è”æƒ³è¯
        related_keywords = keyword_categories[category]
        search_volume = [random.randint(1000, 50000) for _ in range(len(related_keywords))]
        
        # åˆ›å»ºæ’åºåçš„å…³é”®è¯å’Œæœç´¢é‡çš„åˆ—è¡¨
        keyword_data = list(zip(related_keywords, search_volume))
        keyword_data.sort(key=lambda x: x[1], reverse=True)
        
        top_keywords = [k for k, _ in keyword_data[:3]]
        
        return {
            "core_keyword": keyword,
            "related_keywords": related_keywords,
            "search_volume": dict(zip(related_keywords, search_volume)),
            "top_recommendations": top_keywords,
            "analysis": f"æœç´¢'{keyword}'çš„ç”¨æˆ·å¤šå…³æ³¨'{top_keywords[0]}'å’Œ'{top_keywords[1]}'ç›¸å…³å†…å®¹ï¼Œå»ºè®®åœ¨è´¦å·æ ‡ç­¾å’Œå†…å®¹ä¸­åŠ å…¥è¿™äº›å…³é”®è¯ä»¥æé«˜æ›å…‰"
        }
    
    async def _arun(self, keyword: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè·å–å…³é”®è¯è”æƒ³è¯"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class SearchUserTool(BaseTool):
    """æœç´¢åŒé¢†åŸŸè´¦å·å·¥å…·"""
    name: str = "search_user"
    description: str = "æœç´¢åŒé¢†åŸŸè´¦å·ï¼Œå¦‚æœç´¢'èŒåœºå¥èº«'æ ‡ç­¾ä¸‹çš„å‰20åè´¦å·ï¼Œåˆ†æäººè®¾åŒè´¨åŒ–é—®é¢˜"
    args_schema: Type[BaseModel] = SearchUserInput
    
    def _run(self, keyword: str, limit: int = 20) -> Dict[str, Any]:
        """
        æœç´¢åŒé¢†åŸŸè´¦å·
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            limit: è¿”å›ç»“æœé™åˆ¶
            
        Returns:
            Dict: è´¦å·åˆ—è¡¨å’Œåˆ†æ
        """
        # æ¨¡æ‹ŸAPIè¿”å›æœç´¢ç»“æœ
        results = []
        persona_keywords = [
            "ä¸“ä¸š", "è¾¾äºº", "åšä¸»", "æ•™ç»ƒ", "è€å¸ˆ", "æµ‹è¯„å¸ˆ", "ç§è‰å®˜", "åˆ›ä½œè€…", 
            "ç”Ÿæ´»å®¶", "è®¾è®¡å¸ˆ", "ç©å®¶", "å¥èº«è¾¾äºº", "æ­é…å¸ˆ", "ç¾å¦†åšä¸»"
        ]
        
        for i in range(limit):
            persona_type = random.choice(persona_keywords)
            follower_count = random.randint(1000, 500000)
            
            results.append({
                "user_id": f"user_{i}_{keyword.replace(' ', '_')}",
                "nickname": f"{keyword}{persona_type}{i+1}å·",
                "follower_count": follower_count,
                "notes_count": random.randint(50, 300),
                "persona_keywords": random.sample(persona_keywords, 3),
                "description": f"ä¸“æ³¨äº{keyword}å†…å®¹åˆ†äº«" if i % 3 != 0 else f"{keyword}é¢†åŸŸåˆ›ä½œè€…ï¼Œæä¾›ä¸“ä¸š{keyword}æŒ‡å¯¼"
            })
        
        # æŒ‰ç²‰ä¸æ•°æ’åº
        results.sort(key=lambda x: x["follower_count"], reverse=True)
        
        # åˆ†æäººè®¾åŒè´¨åŒ–é—®é¢˜
        common_keywords = set()
        for result in results[:5]:  # åªåˆ†æå‰5ä¸ªè´¦å·
            common_keywords.update(result["persona_keywords"])
        
        return {
            "accounts": results,
            "analysis": {
                "total_found": len(results),
                "common_persona_keywords": list(common_keywords),
                "homogenization_issues": f"åœ¨{keyword}é¢†åŸŸå‰20åè´¦å·ä¸­ï¼Œ{round(len(results) * 0.7)}ä¸ªä½¿ç”¨ç±»ä¼¼äººè®¾å®šä½ï¼Œå»ºè®®é¿å…ä½¿ç”¨{list(common_keywords)[:3]}ç­‰é«˜é¢‘äººè®¾å…³é”®è¯ï¼Œå¯»æ‰¾å·®å¼‚åŒ–å®šä½"
            }
        }
    
    async def _arun(self, keyword: str, limit: int = 20) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œæœç´¢åŒé¢†åŸŸè´¦å·"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class GetUserAllNotesTool(BaseTool):
    """è·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°å·¥å…·"""
    name: str = "get_user_all_notes"
    description: str = "æå–ç«å“ç¬”è®°å†…å®¹ï¼Œè¯†åˆ«é«˜é¢‘å‡ºç°çš„äººè®¾å…³é”®è¯ï¼ˆå¦‚'ä¸“ä¸šæ•™ç»ƒ'ã€'å®å¦ˆ'ï¼‰ï¼Œé¿å…å®šä½é‡å¤"
    args_schema: Type[BaseModel] = UserAllNotesInput
    
    def _run(self, user_id: str, limit: int = 10) -> Dict[str, Any]:
        """
        è·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: è¿”å›ç»“æœé™åˆ¶
            
        Returns:
            Dict: åŒ…å«ç¬”è®°åˆ—è¡¨å’Œåˆ†æ
        """
        # æ¨¡æ‹Ÿç¬”è®°ä¸»é¢˜
        topics = ["äº§å“æµ‹è¯„", "ä½¿ç”¨æ•™ç¨‹", "ç»éªŒåˆ†äº«", "é—®é¢˜è§£å†³", "æ–°å“æ¨è", "ç§‘æ™®çŸ¥è¯†", "è¶‹åŠ¿åˆ†æ"]
        
        # æ¨¡æ‹Ÿç¬”è®°æ ¼å¼
        formats = ["å›¾æ–‡æµ‹è¯„", "è§†é¢‘è®°å½•", "æ¸…å•æ€»ç»“", "é—®ç­”è§£æ", "æ­¥éª¤æ•™ç¨‹", "å¯¹æ¯”åˆ†æ"]
        
        # ç”Ÿæˆéšæœºç¬”è®°æ•°æ®
        notes = []
        for i in range(limit):
            topic = random.choice(topics)
            note_format = random.choice(formats)
            
            notes.append({
                "note_id": f"note_{i}_{user_id}",
                "title": f"{topic}ï¼š{note_format}{i+1}",
                "type": "å›¾æ–‡" if random.random() > 0.3 else "è§†é¢‘",
                "likes": random.randint(10, 5000),
                "comments": random.randint(0, 200),
                "collects": random.randint(5, 500),
                "create_time": f"2023-{random.randint(1, 12)}-{random.randint(1, 28)}",
                "topic": topic,
                "format": note_format
            })
        
        # åˆ†æä¸»é¢˜åˆ†å¸ƒ
        topic_distribution = {}
        for note in notes:
            topic = note["topic"]
            topic_distribution[topic] = topic_distribution.get(topic, 0) + 1
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        for topic in topic_distribution:
            topic_distribution[topic] = round(topic_distribution[topic] / len(notes) * 100)
        
        # åˆ†æé«˜é¢‘äººè®¾å…³é”®è¯
        format_distribution = {}
        for note in notes:
            format_name = note["format"]
            format_distribution[format_name] = format_distribution.get(format_name, 0) + 1
        
        return {
            "user_id": user_id,
            "notes_count": len(notes),
            "notes": notes,
            "analysis": {
                "topic_distribution": topic_distribution,
                "format_distribution": format_distribution,
                "top_performing_topics": [k for k, v in sorted(topic_distribution.items(), key=lambda item: item[1], reverse=True)][:3],
                "persona_keywords": ["ä¸“ä¸š", "å®ç”¨", "æ·±åº¦" if random.random() > 0.5 else "é€šä¿—æ˜“æ‡‚"],
                "content_focus": f"å†…å®¹{round(topic_distribution.get('äº§å“æµ‹è¯„', 0) + topic_distribution.get('ç»éªŒåˆ†äº«', 0))}%é›†ä¸­åœ¨äº§å“æµ‹è¯„å’Œç»éªŒåˆ†äº«ï¼Œå»ºè®®å¼€æ‹“æ›´å¤š{random.choice(list(set(topics) - {'äº§å“æµ‹è¯„', 'ç»éªŒåˆ†äº«'}))}ç±»å†…å®¹"
            }
        }
    
    async def _arun(self, user_id: str, limit: int = 50) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè·å–ç”¨æˆ·æ‰€æœ‰ç¬”è®°"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class GetHomefeedRecommendTool(BaseTool):
    """è·å–é¦–é¡µæ¨èå†…å®¹å·¥å…·"""
    name: str = "get_homefeed_recommend_by_num"
    description: str = "è·å–æŒ‡å®šå“ç±»çš„çƒ­é—¨æ¨èç¬”è®°ï¼Œå¦‚è·å–å¥èº«é¢‘é“Top50æ¨èç¬”è®°ï¼Œåˆ†æè¿‘æœŸçˆ†æ¬¾å†…å®¹å½¢å¼"
    args_schema: Type[BaseModel] = HomefeedRecommendInput
    
    def _run(self, category: str, num: int = 50) -> Dict[str, Any]:
        """
        è·å–é¦–é¡µæ¨èå†…å®¹
        
        Args:
            category: å†…å®¹å“ç±»
            num: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            Dict: æ¨èå†…å®¹åˆ—è¡¨å’Œåˆ†æ
        """
        # å†…å®¹å½¢å¼åˆ—è¡¨
        content_forms = [
            "é—®é¢˜-è§£å†³æ–¹æ¡ˆå›¾æ–‡", "æ­¥éª¤åˆ†è§£å›¾æ–‡", "å¯¹æ¯”å›¾æ–‡", "æ¸…å•å‹å›¾æ–‡", 
            "è·Ÿç»ƒè§†é¢‘", "Vlogè§†é¢‘", "æµ‹è¯„è§†é¢‘", "çŸ¥è¯†ç‚¹è®²è§£è§†é¢‘"
        ]
        
        # ç”Ÿæˆéšæœºæ¨èå†…å®¹
        recommendations = []
        for i in range(num):
            content_form = random.choice(content_forms)
            is_video = "è§†é¢‘" in content_form
            
            recommendations.append({
                "note_id": f"note_{i}_{category.replace(' ', '_')}",
                "title": f"{random.choice(['å¦‚ä½•', 'ä¸ºä»€ä¹ˆ', 'è¿™æ ·åš', 'å¿…çœ‹'])}ï¼š{category}{content_form}å†…å®¹{i+1}",
                "type": "è§†é¢‘" if is_video else "å›¾æ–‡",
                "likes": random.randint(500, 50000),
                "comments": random.randint(10, 2000),
                "collects": random.randint(100, 10000),
                "create_time": f"2023-{random.randint(1, 12)}-{random.randint(1, 28)}",
                "content_form": content_form,
                "has_purchase": random.choice([True, False, False, False])  # 25%æ¦‚ç‡æœ‰è´­ç‰©é“¾æ¥
            })
        
        # æŒ‰äº’åŠ¨é‡æ’åº
        recommendations.sort(key=lambda x: x["likes"] + x["comments"]*3 + x["collects"]*2, reverse=True)
        
        # åˆ†æå†…å®¹å½¢å¼åˆ†å¸ƒ
        form_distribution = {}
        for rec in recommendations:
            form = rec["content_form"]
            form_distribution[form] = form_distribution.get(form, 0) + 1
        
        # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
        for form in form_distribution:
            form_distribution[form] = round(form_distribution[form] / len(recommendations) * 100)
        
        # åˆ†æè§†é¢‘ä¸å›¾æ–‡æ¯”ä¾‹
        video_count = sum(1 for rec in recommendations if rec["type"] == "è§†é¢‘")
        video_percentage = round(video_count / len(recommendations) * 100)
        
        # åˆ†ææ ‡é¢˜ç‰¹å¾
        title_features = []
        if any("å¦‚ä½•" in rec["title"] for rec in recommendations[:10]):
            title_features.append("é—®é¢˜è§£å†³å‹")
        if any("å¿…çœ‹" in rec["title"] for rec in recommendations[:10]):
            title_features.append("å¼ºè°ƒé‡è¦æ€§")
        if any(str(n) in rec["title"] for n in range(1, 10) for rec in recommendations[:10]):
            title_features.append("æ•°å­—å¼•å¯¼å‹")
        
        return {
            "category": category,
            "total_recommendations": len(recommendations),
            "top_recommendations": recommendations[:10],
            "analysis": {
                "content_form_distribution": form_distribution,
                "video_percentage": video_percentage,
                "image_text_percentage": 100 - video_percentage,
                "title_features": title_features,
                "trending_forms": [k for k, v in sorted(form_distribution.items(), key=lambda item: item[1], reverse=True)][:3],
                "insight": f"åœ¨{category}å“ç±»ä¸­ï¼Œ{[k for k, v in sorted(form_distribution.items(), key=lambda item: item[1], reverse=True)][0]}æœ€å—æ¬¢è¿ï¼Œå æ¯”{form_distribution[[k for k, v in sorted(form_distribution.items(), key=lambda item: item[1], reverse=True)][0]]}%ï¼Œå»ºè®®ä¼˜å…ˆé‡‡ç”¨æ­¤å†…å®¹å½¢å¼"
            }
        }
    
    async def _arun(self, category: str, num: int = 50) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè·å–é¦–é¡µæ¨èå†…å®¹"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class SearchNoteTool(BaseTool):
    """æœç´¢ç¬”è®°å·¥å…·"""
    name: str = "search_note"
    description: str = "æŒ‰å…³é”®è¯æœç´¢ç¬”è®°ï¼Œå¦‚æŒ‰'èŒåœºå¥èº«'æœç´¢è¿‘30å¤©å†…å®¹ï¼Œç­›é€‰å‡ºç‚¹èµ>5000çš„ç¬”è®°ï¼Œæç‚¼é«˜é¢‘é€‰é¢˜"
    args_schema: Type[BaseModel] = SearchNoteInput
    
    def _run(self, keyword: str, days: int = 30, min_likes: int = 0, sort_by: str = "hot") -> Dict[str, Any]:
        """
        æœç´¢ç¬”è®°
        
        Args:
            keyword: æœç´¢å…³é”®è¯
            days: é™å®šå¤©æ•°èŒƒå›´
            min_likes: æœ€å°ç‚¹èµæ•°
            sort_by: æ’åºæ–¹å¼ï¼Œhotæˆ–time
            
        Returns:
            Dict: ç¬”è®°åˆ—è¡¨å’Œåˆ†æ
        """
        # ç”Ÿæˆéšæœºæœç´¢ç»“æœ
        num_results = random.randint(30, 100)
        results = []
        
        # å¸¸è§æ ‡é¢˜ç»“æ„
        title_structures = [
            "æ•°å­—+ç—›ç‚¹+è§£å†³æ–¹æ¡ˆ",
            "ç–‘é—®å¥+ç­”æ¡ˆæš—ç¤º",
            "å¼ºè°ƒè¯+æ ¸å¿ƒåˆ©ç›Šç‚¹",
            "ç´§æ€¥æ„Ÿ+å…³é”®ç»“æœ",
            "å¯¹æ¯”å‹+è½¬æŠ˜"
        ]
        
        # å†…å®¹ç±»å‹
        content_types = ["æ•™ç¨‹", "åˆ†äº«", "æµ‹è¯„", "è®°å½•", "æ€»ç»“", "æ”»ç•¥"]
        
        # ç”Ÿæˆæœç´¢ç»“æœ
        for i in range(num_results):
            likes = random.randint(10, 20000)
            if likes < min_likes:
                likes = min_likes + random.randint(0, 1000)
                
            content_type = random.choice(content_types)
            title_structure = random.choice(title_structures)
            
            # æ ¹æ®æ ‡é¢˜ç»“æ„ç”Ÿæˆæ ‡é¢˜
            if "æ•°å­—" in title_structure:
                title = f"{random.randint(1, 10)}ä¸ª{keyword}{content_type}æ–¹æ³•"
            elif "ç–‘é—®å¥" in title_structure:
                title = f"å¦‚ä½•æŒæ¡{keyword}çš„{content_type}æŠ€å·§ï¼Ÿ"
            elif "å¼ºè°ƒè¯" in title_structure:
                title = f"å¿…å­¦ï¼{keyword}{content_type}ç»æŠ€"
            elif "ç´§æ€¥æ„Ÿ" in title_structure:
                title = f"é€Ÿæ”¶è—ï¼{keyword}é«˜æ•ˆ{content_type}"
            else:
                title = f"ä»¥å‰vsç°åœ¨ï¼š{keyword}{content_type}æ–°æ–¹æ³•"
            
            results.append({
                "note_id": f"note_search_{i}",
                "title": title,
                "type": "è§†é¢‘" if random.random() > 0.6 else "å›¾æ–‡",
                "likes": likes,
                "comments": random.randint(5, min(likes//2, 1000)),
                "collects": random.randint(10, min(likes//1.5, 2000)),
                "create_time": f"2023-{random.randint(1, 12)}-{random.randint(1, 28)}",
                "content_type": content_type,
                "title_structure": title_structure
            })
        
        # æŒ‰ç‚¹èµæ•°æ’åº
        if sort_by == "hot":
            results.sort(key=lambda x: x["likes"], reverse=True)
        else:
            # æŒ‰æ—¶é—´æ’åºï¼Œè¿™é‡Œç®€å•æ¨¡æ‹Ÿ
            random.shuffle(results)
        
        # ç­›é€‰æ»¡è¶³ç‚¹èµè¦æ±‚çš„ç¬”è®°
        filtered_results = [r for r in results if r["likes"] >= min_likes]
        
        # åˆ†æé«˜é¢‘é€‰é¢˜
        topic_count = {}
        for result in filtered_results:
            topic = result["content_type"]
            topic_count[topic] = topic_count.get(topic, 0) + 1
        
        # åˆ†ææ ‡é¢˜ç»“æ„
        structure_count = {}
        for result in filtered_results:
            structure = result["title_structure"]
            structure_count[structure] = structure_count.get(structure, 0) + 1
        
        return {
            "keyword": keyword,
            "days_range": days,
            "min_likes": min_likes,
            "total_results": len(filtered_results),
            "notes": filtered_results[:20],  # åªè¿”å›å‰20æ¡ç»“æœ
            "analysis": {
                "popular_topics": {k: round(v/len(filtered_results)*100) for k, v in sorted(topic_count.items(), key=lambda item: item[1], reverse=True)},
                "effective_title_structures": {k: round(v/len(filtered_results)*100) for k, v in sorted(structure_count.items(), key=lambda item: item[1], reverse=True)},
                "high_engagement_topics": [k for k, v in sorted(topic_count.items(), key=lambda item: item[1], reverse=True)][:3],
                "recommendation": f"å»ºè®®ä¼˜å…ˆåˆ›ä½œ{[k for k, v in sorted(topic_count.items(), key=lambda item: item[1], reverse=True)][0]}ç±»å‹å†…å®¹ï¼Œä½¿ç”¨{[k for k, v in sorted(structure_count.items(), key=lambda item: item[1], reverse=True)][0]}æ ‡é¢˜ç»“æ„ï¼Œå¯æ˜¾è‘—æé«˜å†…å®¹æ›å…‰åº¦"
            }
        }
    
    async def _arun(self, keyword: str, days: int = 30, min_likes: int = 0, sort_by: str = "hot") -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œæœç´¢ç¬”è®°"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class GetNoteInfoTool(BaseTool):
    """è·å–ç¬”è®°è¯¦æƒ…å·¥å…·"""
    name: str = "get_note_info"
    description: str = "è§£æå•ç¯‡çˆ†æ¬¾ç¬”è®°çš„æ ‡é¢˜ç»“æ„å’Œäº’åŠ¨æ•°æ®ï¼Œæç‚¼å¯å¤ç”¨çš„åˆ›ä½œæ¨¡æ¿"
    args_schema: Type[BaseModel] = NoteInfoInput
    
    def _run(self, note_id: str) -> Dict[str, Any]:
        """
        è·å–ç¬”è®°è¯¦æƒ…
        
        Args:
            note_id: ç¬”è®°ID
            
        Returns:
            Dict: ç¬”è®°è¯¦æƒ…
        """
        # æ¨¡æ‹Ÿç¬”è®°è¯¦æƒ…
        note_type = "è§†é¢‘" if random.random() > 0.6 else "å›¾æ–‡"
        likes = random.randint(500, 50000)
        
        # æ ‡é¢˜ç»“æ„ç±»å‹
        title_structures = {
            "æ•°å­—å¼•å¯¼å‹": f"{random.randint(1, 10)}ä¸ªå°æŠ€å·§è®©ä½ è½»æ¾æŒæ¡",
            "é—®é¢˜è§£å†³å‹": "å¦‚ä½•è§£å†³é•¿ä¹…å›°æ‰°çš„é—®é¢˜ï¼Ÿ",
            "åˆ©ç›Šæš—ç¤ºå‹": "å­¦ä¼šè¿™ä¸ªæŠ€å·§ï¼Œæ•ˆç‡æå‡300%",
            "ç´§æ€¥æ„Ÿå‹": "å¿…çœ‹ï¼è¿™äº›é”™è¯¯ä½ ä¸€å®šåœ¨çŠ¯",
            "å¯¹æ¯”è½¬æŠ˜å‹": "å¯¹æ¯”ï¼šä»å…¥é—¨åˆ°ç²¾é€šçš„èœ•å˜"
        }
        
        structure_type = random.choice(list(title_structures.keys()))
        title = title_structures[structure_type]
        
        # å†…å®¹ç»“æ„
        content_structure = {
            "å¼•è¨€": "ç‚¹æ˜ç—›ç‚¹ï¼Œå¼•å‘å…±é¸£",
            "ä¸»ä½“": "åˆ†æ­¥éª¤/åˆ†ç‚¹å±•ç¤ºæ ¸å¿ƒå†…å®¹",
            "ç»“å°¾": "æ€»ç»“è¦ç‚¹ï¼Œå¼•å¯¼äº’åŠ¨/å…³æ³¨"
        }
        
        # äº’åŠ¨æ•°æ®
        interaction_data = {
            "likes": likes,
            "comments": random.randint(10, min(likes//3, 2000)),
            "collects": random.randint(50, min(likes//2, 5000)),
            "shares": random.randint(5, min(likes//4, 1000))
        }
        
        # ç”¨æˆ·è¯„è®ºå…³é”®è¯
        comment_keywords = ["å®ç”¨", "å¹²è´§", "å­¦åˆ°äº†", "æ„Ÿè°¢åˆ†äº«", "æ”¶è—äº†"]
        
        return {
            "note_id": note_id,
            "title": title,
            "title_structure": structure_type,
            "type": note_type,
            "content_structure": content_structure,
            "interaction_data": interaction_data,
            "comment_keywords": random.sample(comment_keywords, 3),
            "analysis": {
                "engagement_rate": round((interaction_data["comments"] + interaction_data["shares"]) / interaction_data["likes"] * 100),
                "collection_rate": round(interaction_data["collects"] / interaction_data["likes"] * 100),
                "title_effectiveness": "é«˜" if interaction_data["likes"] > 5000 else "ä¸­",
                "recommended_improvement": f"å»ºè®®åœ¨{random.choice(['æ ‡é¢˜', 'å¼€å¤´', 'ç»“å°¾'])}å¢åŠ {random.choice(['ç”¨æˆ·å¼•å¯¼', 'æ•°æ®æ”¯æŒ', 'æƒ…æ„Ÿå…±é¸£'])}å…ƒç´ ï¼Œæå‡äº’åŠ¨ç‡"
            }
        }
    
    async def _arun(self, note_id: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè·å–ç¬”è®°è¯¦æƒ…"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

class GetNoteNoWaterVideoTool(BaseTool):
    """è·å–æ— æ°´å°è§†é¢‘å·¥å…·"""
    name: str = "get_note_no_water_video"
    description: str = "è§£æçˆ†æ¬¾è§†é¢‘ç¬”è®°çš„æ— æ°´å°é“¾æ¥ï¼Œç”¨äºäºŒæ¬¡åˆ›ä½œå‚è€ƒ"
    args_schema: Type[BaseModel] = NoWaterVideoInput
    
    def _run(self, note_id: str) -> Dict[str, Any]:
        """
        è·å–ç¬”è®°æ— æ°´å°è§†é¢‘é“¾æ¥
        
        Args:
            note_id: ç¬”è®°ID
            
        Returns:
            Dict: æ— æ°´å°è§†é¢‘ä¿¡æ¯
        """
        return {
            "note_id": note_id,
            "video_url": f"https://example.com/xhs/video/{note_id}.mp4",
            "duration": random.randint(15, 180),
            "resolution": random.choice(["1080p", "720p"]),
            "message": "è§†é¢‘é“¾æ¥å·²ç”Ÿæˆï¼Œä»…ä¾›å­¦ä¹ å‚è€ƒ"
        }
    
    async def _arun(self, note_id: str) -> Dict[str, Any]:
        """å¼‚æ­¥æ‰§è¡Œè·å–æ— æ°´å°è§†é¢‘"""
        raise NotImplementedError("æš‚ä¸æ”¯æŒå¼‚æ­¥æ“ä½œ")

# è¾…åŠ©æ–¹æ³•ï¼Œåˆ›å»ºå·¥å…·é›†åˆ
def get_account_profile_tools() -> List[BaseTool]:
    """è·å–è´¦å·äººè®¾ç›¸å…³å·¥å…·é›†åˆ"""
    return [
        GetUserInfoTool(),
        GetSearchKeywordTool()
    ]

def get_persona_builder_tools() -> List[BaseTool]:
    """è·å–äººè®¾æ„å»ºç›¸å…³å·¥å…·é›†åˆ"""
    return [
        SearchUserTool(),
        GetUserAllNotesTool()
    ]

def get_content_planner_tools() -> List[BaseTool]:
    """è·å–å†…å®¹è§„åˆ’ç›¸å…³å·¥å…·é›†åˆ"""
    return [
        GetHomefeedRecommendTool(),
        SearchNoteTool()
    ]

def get_platform_trend_tools() -> List[BaseTool]:
    """è·å–å¹³å°è¶‹åŠ¿åˆ†æç›¸å…³å·¥å…·é›†åˆ"""
    return [
        GetHomefeedRecommendTool(),
        SearchNoteTool()
    ]

def get_content_style_tools() -> List[BaseTool]:
    """è·å–å†…å®¹é£æ ¼åˆ†æç›¸å…³å·¥å…·é›†åˆ"""
    return [
        GetUserAllNotesTool(),
        GetNoteInfoTool()
    ]

def get_content_creator_tools() -> List[BaseTool]:
    """è·å–å†…å®¹åˆ›ä½œç›¸å…³å·¥å…·é›†åˆ"""
    return [
        GetNoteNoWaterVideoTool(),
        GetNoteInfoTool()
    ]
