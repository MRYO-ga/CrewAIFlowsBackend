# èŠå¤©APIï¼ˆç®€åŒ–ç‰ˆï¼‰
from fastapi import APIRouter

router = APIRouter(prefix="/api/chat-db", tags=["èŠå¤©æ•°æ®åº“"])

@router.get("/messages")
async def get_chat_messages():
    """è·å–èŠå¤©æ¶ˆæ¯åˆ—è¡¨"""
    return {"message": "èŠå¤©æ•°æ®åº“åŠŸèƒ½å¼€å‘ä¸­"}

@router.post("/messages")
async def save_chat_message():
    """ä¿å­˜èŠå¤©æ¶ˆæ¯"""
    return {"message": "èŠå¤©æ¶ˆæ¯ä¿å­˜åŠŸèƒ½å¼€å‘ä¸­"}

# chat APIè·¯ç”±æ¨¡å— - å¤„ç†æ™ºèƒ½å¯¹è¯å’Œä¼˜åŒ–ç›¸å…³çš„APIæ¥å£

from fastapi import APIRouter, HTTPException, Query
from fastapi.responses import StreamingResponse
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any
import json
from utils.myLLM import interact_with_intent_agent
from utils.smart_data_manager import smart_data_manager
from utils.persona_prompts import get_persona_prompt, persona_manager

# åˆ›å»ºå…¨å±€èŠå¤©æœåŠ¡å®ä¾‹
from services.chat_service import ChatService
chat_service = ChatService()

# åˆ›å»ºè·¯ç”±å™¨
chat_router = APIRouter(prefix="/api", tags=["chat"])

# å®šä¹‰å¯¹è¯è¯·æ±‚æ¨¡å‹
class ChatRequest(BaseModel):
    """å¯¹è¯è¯·æ±‚æ¨¡å‹"""
    user_input: str = Field(..., description="ç”¨æˆ·è¾“å…¥çš„æ¶ˆæ¯")
    conversation_history: Optional[List[Dict[str, Any]]] = Field(None, description="å¯¹è¯å†å²")
    user_id: Optional[str] = Field("default_user", description="ç”¨æˆ·ID")
    model: Optional[str] = Field("gpt-4o-mini", description="ä½¿ç”¨çš„AIæ¨¡å‹")
    attached_data: Optional[List[Dict[str, Any]]] = Field(None, description="é™„åŠ çš„å¼•ç”¨æ•°æ®")
    data_references: Optional[List[Dict[str, Any]]] = Field(None, description="æ•°æ®å¼•ç”¨ä¿¡æ¯")


# å®šä¹‰æ™ºèƒ½ä¼˜åŒ–è¯·æ±‚æ¨¡å‹
class OptimizationRequest(BaseModel):
    """æ™ºèƒ½ä¼˜åŒ–è¯·æ±‚æ¨¡å‹"""
    user_id: str = Field(..., description="ç”¨æˆ·ID")
    optimization_type: str = Field(..., description="ä¼˜åŒ–ç±»å‹ï¼šaccount_info, content_strategy, publishing_plan")
    target_area: Optional[str] = Field(None, description="å…·ä½“ä¼˜åŒ–åŒºåŸŸ")


@chat_router.post("/chat")
async def chat_with_agent(request: ChatRequest):
    """ç®€å•èŠå¤©æ¥å£ï¼ˆéæµå¼ï¼‰"""
    try:
        print(f"æ”¶åˆ°éæµå¼èŠå¤©è¯·æ±‚ï¼Œç”¨æˆ·ID: {request.user_id}")
        print(f"ç”¨æˆ·è¾“å…¥: {request.user_input}")
        
        # å¤„ç†é™„åŠ çš„å¼•ç”¨æ•°æ®å’Œä¸Šä¸‹æ–‡
        enhanced_input = request.user_input
        references = []
        context_data = None
        
        if request.attached_data and len(request.attached_data) > 0:
            print(f"å‘ç°é™„åŠ æ•°æ®: {len(request.attached_data)} é¡¹")
            
            # ç›´æ¥å°†æ•°æ®è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œä¸è¿›è¡Œå¤æ‚æ ¼å¼åŒ–
            reference_context = "\n\n[å¼•ç”¨æ•°æ®]:\n"
            for i, data in enumerate(request.attached_data, 1):
                data_type = data.get('type', 'unknown')
                data_info = data.get('data', {})
                
                # æ£€æµ‹æ˜¯å¦ä¸ºä¸Šä¸‹æ–‡æ•°æ®
                if data_type == 'persona_context':
                    context_data = data_info
                    print(f"ğŸ­ æ£€æµ‹åˆ°äººè®¾ä¸Šä¸‹æ–‡: {data_info.get('constructionPhase', 'unknown')}")
                    continue
                
                reference_context += f"\n{i}. æ•°æ®ç±»å‹: {data_type}\n"
                reference_context += f"   æ•°æ®å†…å®¹: {str(data_info)}\n"
                
                # ç®€åŒ–referencesæ„å»º
                references.append({
                    "id": data_info.get('id', data_info.get('note_id', '')),
                    "title": data_info.get('name', data_info.get('title', 'æ•°æ®é¡¹')),
                    "author": data_type,
                    "url": f"#{data_type}-{data_info.get('id', '')}",
                    "description": f"ç±»å‹: {data_type}"
                })
            
            enhanced_input = request.user_input + reference_context
            print(f"å¢å¼ºè¾“å…¥é•¿åº¦: {len(enhanced_input)}")
        
            # æ ¹æ®ä¸Šä¸‹æ–‡è·å–å¯¹åº”çš„äººè®¾æç¤ºè¯
            if context_data:
                persona_prompt = get_persona_prompt(context_data, request.user_input)
                print(f"ğŸ­ ä½¿ç”¨åœºæ™¯åŒ–äººè®¾æç¤ºè¯: {persona_prompt}")
                
                # ä½¿ç”¨äººè®¾åŒ–çš„èŠå¤©æœåŠ¡
                response = await chat_service.simple_chat_with_persona(
                    user_input=enhanced_input,
                    user_id=request.user_id,
                    model=request.model,
                    conversation_history=request.conversation_history,
                    persona_prompt=persona_prompt
                )
                
                print(f"ğŸ­ äººè®¾èŠå¤©æœåŠ¡è¿”å›ç»“æœ: {type(response)}")
                print(f"ğŸ­ äººè®¾èŠå¤©å“åº”å†…å®¹: {response}")
                print(f"ğŸ­ äººè®¾èŠå¤©å“åº”é•¿åº¦: {len(response) if response else 0}")
                
                # è§£æAIè¿”å›çš„JSONç»“æ„åŒ–æ•°æ®
                structured_data = None
                try:
                    # å°è¯•è§£æAIè¿”å›çš„JSON
                    import re
                    
                    # é¦–å…ˆå°è¯•å¯»æ‰¾JSONä»£ç å—
                    json_code_block = re.search(r'```json\s*(\{.*?\})\s*```', response, re.DOTALL)
                    if json_code_block:
                        json_str = json_code_block.group(1)
                        print(f"ğŸ­ æ‰¾åˆ°JSONä»£ç å—")
                    else:
                        # å¦‚æœæ²¡æœ‰ä»£ç å—ï¼Œå¯»æ‰¾ä»»ä½•JSONå¯¹è±¡
                        json_match = re.search(r'\{[^{}]*(?:\{[^{}]*\}[^{}]*)*\}', response, re.DOTALL)
                        if json_match:
                            json_str = json_match.group(0)
                            print(f"ğŸ­ æ‰¾åˆ°JSONå¯¹è±¡")
                        else:
                            json_str = None
                            print("ğŸ­ æœªæ‰¾åˆ°JSONæ ¼å¼")
                    
                    if json_str:
                        # å°è¯•è§£æJSON
                        structured_data = json.loads(json_str)
                        print(f"ğŸ­ æˆåŠŸè§£æç»“æ„åŒ–æ•°æ®")
                        
                        # éªŒè¯å¿…è¦å­—æ®µ
                        if not isinstance(structured_data, dict):
                            print("ğŸ­ JSONä¸æ˜¯å­—å…¸æ ¼å¼ï¼Œå¿½ç•¥")
                            structured_data = None
                        elif 'questions' not in structured_data and 'message' not in structured_data:
                            print("ğŸ­ JSONç¼ºå°‘å¿…è¦å­—æ®µï¼Œå¿½ç•¥")
                            structured_data = None
                        else:
                            print(f"ğŸ­ JSONéªŒè¯é€šè¿‡ï¼ŒåŒ…å«å­—æ®µ: {list(structured_data.keys())}")
                    
                except json.JSONDecodeError as e:
                    print(f"ğŸ­ JSONè§£æå¤±è´¥: {e}")
                    structured_data = None
                except Exception as e:
                    print(f"ğŸ­ è§£æè¿‡ç¨‹å‡ºé”™: {e}")
                    structured_data = None
                
                # è¿”å›äººè®¾åŒ–èŠå¤©çš„å“åº” - ç®€åŒ–å“åº”ç»“æ„ï¼Œé¿å…é‡å¤
                result = {
                    "status": "success",
                    "reply": response,  # å§‹ç»ˆåŒ…å«åŸå§‹å“åº”
                    "final_answer": response,
                    "structured_data": structured_data,
                    "references": references,
                    "hasData": len(references) > 0,
                    "dataType": "persona_chat",
                    "data": {
                        "type": "persona_chat",
                        "reference_count": len(references),
                        "persona_context": context_data.get('constructionPhase', 'unknown'),
                        "structured_response": structured_data is not None,
                        "has_questions": structured_data and 'questions' in structured_data,
                        "questions_count": len(structured_data.get('questions', [])) if structured_data else 0
                    }
                }
                
                print(f"ğŸ­ å³å°†è¿”å›çš„å®Œæ•´ç»“æœ: {result}")
                return result
        else:
            # ä½¿ç”¨é»˜è®¤èŠå¤©æœåŠ¡
            response = await chat_service.simple_chat(
                user_input=enhanced_input,
                user_id=request.user_id,
                model=request.model,
                conversation_history=request.conversation_history
            )
            
            return {
                "status": "success",
                "reply": response,
                "final_answer": response,
                "references": references,
                "hasData": len(references) > 0,
                "dataType": "note_reference" if len(references) > 0 else None,
                "data": {
                    "type": "simple_chat",
                    "reference_count": len(references)
                }
            }
        
    except Exception as e:
        print(f"éæµå¼èŠå¤©å¤„ç†å‡ºé”™: {str(e)}")
        return {
            "status": "error",
            "reply": f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯: {str(e)}",
            "error": str(e)
        }


# @chat_router.post("/optimize")
# async def optimize_user_data(request: OptimizationRequest):
#     """ä¸“é—¨çš„ç”¨æˆ·æ•°æ®ä¼˜åŒ–æ¥å£"""
#     try:
#         print(f"æ”¶åˆ°ä¼˜åŒ–è¯·æ±‚ï¼Œç”¨æˆ·ID: {request.user_id}, ä¼˜åŒ–ç±»å‹: {request.optimization_type}")
        
#         # è·å–ç”¨æˆ·æ•°æ®ä¸Šä¸‹æ–‡
#         user_context = smart_data_manager.get_user_data_context(request.user_id)
        
#         # æ‰§è¡Œæ™ºèƒ½åˆ†æå’Œä¼˜åŒ–
#         optimization_result = smart_data_manager.analyze_and_optimize(
#             request.user_id,
#             request.optimization_type,
#             user_context
#         )
        
#         return {
#             "status": "success",
#             "user_id": request.user_id,
#             "optimization_type": request.optimization_type,
#             "result": optimization_result,
#             "timestamp": optimization_result.get("timestamp")
#         }
        
#     except Exception as e:
#         print(f"ä¼˜åŒ–å¤„ç†å‡ºé”™: {str(e)}")
#         raise HTTPException(status_code=500, detail=str(e))


@chat_router.get("/user-context/{user_id}")
async def get_user_context(user_id: str, data_type: str = "all"):
    """è·å–ç”¨æˆ·çš„æ•°æ®ä¸Šä¸‹æ–‡"""
    try:
        print(f"è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡ï¼Œç”¨æˆ·ID: {user_id}, æ•°æ®ç±»å‹: {data_type}")
        
        # é€šè¿‡MCPè·å–ç”¨æˆ·æ•°æ®
        user_context = smart_data_manager.get_user_data_context(user_id, data_type)
        
        return {
            "status": "success",
            "user_id": user_id,
            "data_type": data_type,
            "context": user_context,
            "summary": {
                "modules_count": len(user_context),
                "available_modules": list(user_context.keys())
            }
        }
        
    except Exception as e:
        print(f"è·å–ç”¨æˆ·ä¸Šä¸‹æ–‡å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))


@chat_router.post("/chat/stream")
async def stream_chat_with_agent(request: ChatRequest):
    """æµå¼èŠå¤©æ¥å£ï¼Œå®æ—¶å±•ç¤ºå¯¹è¯è¿‡ç¨‹"""
    
    async def generate_stream():
        try:
            print(f"æ”¶åˆ°æµå¼èŠå¤©è¯·æ±‚ï¼Œç”¨æˆ·ID: {request.user_id}")
            print(f"ç”¨æˆ·è¾“å…¥: {request.user_input}")
            
            # å¤„ç†é™„åŠ çš„å¼•ç”¨æ•°æ®
            enhanced_input = request.user_input
            
            if request.attached_data and len(request.attached_data) > 0:
                print(f"ğŸ“ å‘ç°é™„åŠ æ•°æ®: {len(request.attached_data)} é¡¹")
                
                # ç›´æ¥å°†æ•°æ®è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œä¸è¿›è¡Œå¤æ‚æ ¼å¼åŒ–
                reference_context = "\n\n[å¼•ç”¨æ•°æ®]:\n"
                for i, data in enumerate(request.attached_data, 1):
                    data_type = data.get('type', 'unknown')
                    data_info = data.get('data', {})
                    
                    print(f"ğŸ“‹ å¤„ç†å¼•ç”¨æ•°æ® {i}: ç±»å‹={data_type}, åç§°={data_info.get('name', 'æœªçŸ¥')}")
                    
                    reference_context += f"\n{i}. æ•°æ®ç±»å‹: {data_type}\n"
                    reference_context += f"   æ•°æ®å†…å®¹: {str(data_info)}\n"
                
                enhanced_input = request.user_input + reference_context
                print(f"âœ… å¢å¼ºè¾“å…¥é•¿åº¦: {len(enhanced_input)}")
            
            async for chunk in chat_service.process_message_stream(
                user_input=enhanced_input,
                user_id=request.user_id,
                model=request.model,
                conversation_history=request.conversation_history,
                attached_data=request.attached_data
            ):
                # å‘é€æœåŠ¡å™¨å‘é€äº‹ä»¶æ ¼å¼
                yield f"data: {json.dumps(chunk, ensure_ascii=False)}\n\n"
                
        except Exception as e:
            error_chunk = {
                "type": "error",
                "content": f"æµå¼å¤„ç†å‡ºé”™: {str(e)}",
                "data": {"error": str(e)},
                "timestamp": ""
            }
            yield f"data: {json.dumps(error_chunk, ensure_ascii=False)}\n\n"
    
    return StreamingResponse(
        generate_stream(),
        media_type="text/event-stream",
        headers={
            "Cache-Control": "no-cache",
            "Connection": "keep-alive",
            "Access-Control-Allow-Origin": "*",
            "Access-Control-Allow-Methods": "GET, POST, OPTIONS",
            "Access-Control-Allow-Headers": "Content-Type"
        }
    )

@chat_router.post("/chat/analyze")
async def analyze_user_request(request: ChatRequest):
    """åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œè¿”å›ä»»åŠ¡æ‹†è§£ç»“æœ"""
    try:
        print(f"åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œç”¨æˆ·ID: {request.user_id}")
        print(f"ç”¨æˆ·è¾“å…¥: {request.user_input}")
        
        # ä½¿ç”¨å…¨å±€çš„chat_serviceå®ä¾‹ï¼Œä¸è¦åˆ›å»ºæ–°çš„
        # åˆ†æç”¨æˆ·è¯·æ±‚ (è¿™ä¸ªæ–¹æ³•å¯èƒ½éœ€è¦æ·»åŠ åˆ°ChatServiceä¸­)
        # task_decomposition = await chat_service.analyze_user_request(request.user_input)
        
        # æš‚æ—¶è¿”å›ç®€å•å“åº”ï¼Œå› ä¸ºanalyze_user_requestæ–¹æ³•å¯èƒ½ä¸å­˜åœ¨
        result = {
            "status": "success",
            "message": "åˆ†æåŠŸèƒ½å¼€å‘ä¸­",
            "data": {
                "task_decomposition": {"steps": [], "requires_tools": False, "tool_names": []},
                "estimated_steps": 0,
                "requires_tools": False,
                "tool_names": []
            }
        }
        
        print("åˆ†æåŠŸèƒ½å¼€å‘ä¸­")
        
        return result
        
    except Exception as e:
        print(f"åˆ†æè¯·æ±‚å‡ºé”™: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@chat_router.get("/chat/mcp-status")
async def get_mcp_status():
    """è·å–MCPè¿æ¥çŠ¶æ€å’Œå¯ç”¨å·¥å…·"""
    try:
        status = await chat_service.get_mcp_status()
        return {
            "status": "success",
            "data": status
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "data": {
                "connected": False,
                "tools_count": 0,
                "tools": []
            }
        }

@chat_router.post("/chat/mcp-reconnect")
async def reconnect_mcp():
    """é‡æ–°è¿æ¥MCPæœåŠ¡å™¨"""
    try:
        success = await chat_service.reconnect_mcp()
        if success:
            status = await chat_service.get_mcp_status()
            return {
                "status": "success",
                "message": "MCPé‡æ–°è¿æ¥æˆåŠŸ",
                "data": status
            }
        else:
            return {
                "status": "error",
                "message": "MCPé‡æ–°è¿æ¥å¤±è´¥",
                "data": {
                    "connected": False,
                    "tools_count": 0,
                    "tools": []
                }
            }
    except Exception as e:
        return {
            "status": "error",
            "message": f"MCPé‡æ–°è¿æ¥å¤±è´¥: {str(e)}",
            "error": str(e)
        }

# å…¼å®¹æ€§æ¥å£ - ä¿æŒåŸæœ‰APIæ¥å£
@chat_router.get("/chat/tools")
async def get_available_tools():
    """è·å–å¯ç”¨å·¥å…·åˆ—è¡¨ï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰"""
    try:
        status = await chat_service.get_mcp_status()
        return {
            "status": "success",
            "tools": status.get("tools", []),
            "count": status.get("tools_count", 0)
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "tools": [],
            "count": 0
        }

@chat_router.get("/chat/context/{user_id}")
async def get_chat_context(user_id: str):
    """è·å–èŠå¤©ä¸Šä¸‹æ–‡ï¼ˆå…¼å®¹æ€§æ¥å£ï¼‰"""
    try:
        status = await chat_service.get_mcp_status()
        return {
            "status": "success",
            "user_id": user_id,
            "context": {
                "mcp_connected": status.get("connected", False),
                "available_tools": status.get("tools", []),
                "tools_count": status.get("tools_count", 0)
            }
        }
    except Exception as e:
        return {
            "status": "error",
            "error": str(e),
            "context": {}
        }

# å ä½ç¬¦æ¥å£
@chat_router.get("/chat/history")
async def get_chat_history():
    """è·å–èŠå¤©å†å²ï¼ˆå¾…å®ç°ï¼‰"""
    return {"message": "èŠå¤©å†å²åŠŸèƒ½å¼€å‘ä¸­"}

@chat_router.post("/chat/save")
async def save_message():
    """ä¿å­˜èŠå¤©æ¶ˆæ¯ï¼ˆå¾…å®ç°ï¼‰"""
    return {"message": "æ¶ˆæ¯ä¿å­˜åŠŸèƒ½å¼€å‘ä¸­"}


@chat_router.get("/chat/references/{user_id}")
async def get_user_references(
    user_id: str, 
    limit: int = Query(20, ge=1, le=100), 
    search: Optional[str] = Query(None)
):
    """è·å–ç”¨æˆ·çš„å¼•ç”¨æ•°æ®ï¼Œä¾›@åŠŸèƒ½ä½¿ç”¨"""
    try:
        from services.mcp_cache_service import mcp_cache_service
        
        # è·å–ç¬”è®°æ•°æ®
        notes = await mcp_cache_service.get_user_notes(user_id, limit)
        
        # å¦‚æœæœ‰æœç´¢å…³é”®è¯ï¼Œè¿›è¡Œè¿‡æ»¤
        if search:
            search_lower = search.lower()
            notes = [
                note for note in notes
                if (note.get('title', '').lower().find(search_lower) >= 0 or
                    note.get('content', '').lower().find(search_lower) >= 0 or
                    note.get('author_name', '').lower().find(search_lower) >= 0)
            ]
        
        # è½¬æ¢ä¸ºå¼•ç”¨æ ¼å¼
        references = []
        for note in notes:
            references.append({
                "id": note.get('note_id', ''),
                "type": "note",
                "name": note.get('title', 'æ— æ ‡é¢˜'),
                "subInfo": f"ä½œè€…ï¼š{note.get('author_name', 'æœªçŸ¥')} | ç‚¹èµï¼š{note.get('likes_count', 0)}",
                "data": note
            })
        
        return {
            "status": "success",
            "data": {
                "references": references,
                "total": len(references),
                "user_id": user_id
            }
        }
        
    except Exception as e:
        print(f"è·å–å¼•ç”¨æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å¼•ç”¨æ•°æ®å¤±è´¥: {str(e)}")


@chat_router.get("/chat/reference-categories/{user_id}")
async def get_reference_categories(user_id: str):
    """è·å–å¼•ç”¨æ•°æ®çš„åˆ†ç±»ï¼Œä¾›ä¾§è¾¹æ å±•ç¤ºä½¿ç”¨"""
    try:
        from services.mcp_cache_service import mcp_cache_service
        
        # è·å–ç”¨æˆ·æ•°æ®
        notes = await mcp_cache_service.get_user_notes(user_id, 100)
        searches = await mcp_cache_service.get_user_searches(user_id, 20)
        
        categories = []
        
        # ç¬”è®°åˆ†ç±»
        if notes:
            note_items = []
            for note in notes[:20]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                note_items.append({
                    "type": "note",
                    "name": note.get('title', 'æ— æ ‡é¢˜'),
                    "subInfo": f"ä½œè€…ï¼š{note.get('author_name', 'æœªçŸ¥')} | ç‚¹èµï¼š{note.get('likes_count', 0)}",
                    "data": note
                })
            
            categories.append({
                "title": "ç¬”è®°æ•°æ®",
                "icon": "FileTextOutlined",
                "items": note_items,
                "total": len(notes)
            })
        
        # æœç´¢å†å²åˆ†ç±»
        if searches:
            search_items = []
            for search in searches[:10]:  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                search_items.append({
                    "type": "search",
                    "name": search.get('keywords', ''),
                    "subInfo": f"ç»“æœï¼š{search.get('total_count', 0)} æ¡",
                    "data": search
                })
            
            categories.append({
                "title": "æœç´¢å†å²",
                "icon": "SearchOutlined", 
                "items": search_items,
                "total": len(searches)
            })
        
        return {
            "status": "success",
            "data": {
                "categories": categories,
                "user_id": user_id
            }
        }
        
    except Exception as e:
        print(f"è·å–å¼•ç”¨åˆ†ç±»å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å¼•ç”¨åˆ†ç±»å¤±è´¥: {str(e)}") 


@chat_router.get("/chat/available-models")
async def get_available_models():
    """è·å–å¯ç”¨çš„AIæ¨¡å‹åˆ—è¡¨"""
    try:
        print("å¼€å§‹è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨...")
        
        # ç›´æ¥å®šä¹‰æ¨¡å‹é…ç½®ï¼Œé¿å…å¯¼å…¥é—®é¢˜
        MODEL_CONFIGS = {
            # OpenAIæ¨¡å‹
            'gpt-4o-mini': {
                'provider': 'openai',
                'model': 'gpt-4o-mini'
            },
            'gpt-4o': {
                'provider': 'openai',
                'model': 'gpt-4o'
            },
            
            # Claudeæ¨¡å‹ï¼ˆé€šè¿‡äº‘é›¾AIçš„å…¼å®¹æ¥å£ï¼‰
            'claude-sonnet-4-20250514': {
                'provider': 'anthropic',
                'model': 'claude-sonnet-4-20250514'
            },
            'claude-3-7-sonnet-20250219-thinking': {
                'provider': 'anthropic',
                'model': 'claude-3-7-sonnet-20250219-thinking'
            },
            'claude-3-5-sonnet-20241022': {
                'provider': 'anthropic',
                'model': 'claude-3-5-sonnet-20241022'
            },
            
            # DeepSeekæ¨¡å‹
            'deepseek-r1-2025-01-20': {
                'provider': 'deepseek',
                'model': 'deepseek-r1-2025-01-20'
            }
        }
        
        print(f"æ‰¾åˆ° {len(MODEL_CONFIGS)} ä¸ªæ¨¡å‹é…ç½®")
        
        models = []
        for model_key, config in MODEL_CONFIGS.items():
            # ç”Ÿæˆå‹å¥½çš„æ ‡ç­¾å
            if model_key == 'gpt-4o-mini':
                label = 'GPT-4o Mini'
            elif model_key == 'gpt-4o':
                label = 'GPT-4o'
            elif 'claude-sonnet-4' in model_key:
                label = 'Claude Sonnet 4'
            elif 'claude-3-7-sonnet' in model_key:
                label = 'Claude 3.7 Sonnet (Thinking)'
            elif 'claude-3-5-sonnet' in model_key:
                label = 'Claude 3.5 Sonnet'
            elif 'deepseek-r1' in model_key:
                label = 'DeepSeek R1'
            else:
                label = model_key.replace('-', ' ').title()
            
            model_info = {
                "value": model_key,
                "label": label,
                "provider": config.get('provider', 'unknown'),
                "model": config.get('model', model_key)
            }
            
            # æ·»åŠ æè¿°ä¿¡æ¯
            if 'gpt-4o-mini' in model_key:
                model_info["description"] = "å¿«é€Ÿã€ç»æµçš„æ¨¡å‹ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯"
            elif 'gpt-4o' in model_key:
                model_info["description"] = "æ›´å¼ºå¤§çš„æ¨ç†èƒ½åŠ›ï¼Œé€‚åˆå¤æ‚ä»»åŠ¡"
            elif 'claude-sonnet-4' in model_key:
                model_info["description"] = "æœ€æ–°Claudeæ¨¡å‹ï¼Œä¼˜ç§€çš„æ¨ç†å’Œåˆ›ä½œèƒ½åŠ›"
            elif 'claude-3-7-sonnet' in model_key:
                model_info["description"] = "å…·æœ‰æ·±åº¦æ€è€ƒèƒ½åŠ›çš„Claudeæ¨¡å‹"
            elif 'claude-3-5-sonnet' in model_key:
                model_info["description"] = "å¹³è¡¡æ€§èƒ½å’Œé€Ÿåº¦çš„Claudeæ¨¡å‹"
            elif 'deepseek-r1' in model_key:
                model_info["description"] = "ä¸­æ–‡ä¼˜åŒ–çš„å¼ºæ¨ç†æ¨¡å‹"
            else:
                model_info["description"] = "é«˜è´¨é‡çš„AIæ¨¡å‹"
            
            models.append(model_info)
        
        print(f"æˆåŠŸæ„å»ºäº† {len(models)} ä¸ªæ¨¡å‹ä¿¡æ¯")
        
        return {
            "status": "success",
            "models": models,
            "total_models": len(models)
        }
        
    except Exception as e:
        print(f"è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨å‡ºé”™: {str(e)}")
        import traceback
        traceback.print_exc()
        
        # è¿”å›é»˜è®¤æ¨¡å‹åˆ—è¡¨ä½œä¸ºåå¤‡
        default_models = [
            {
                "value": "gpt-4o-mini",
                "label": "GPT-4o Mini",
                "provider": "openai",
                "description": "å¿«é€Ÿã€ç»æµçš„æ¨¡å‹ï¼Œé€‚åˆæ—¥å¸¸å¯¹è¯"
            }
        ]
        
        return {
            "status": "success",
            "models": default_models,
            "total_models": len(default_models),
            "error": f"ä½¿ç”¨é»˜è®¤é…ç½®: {str(e)}"
        }