"""
ç®€åŒ–çš„LLMæœåŠ¡æ¨¡å—
è®©LLMç›´æ¥å†³å®šæ˜¯å¦ä½¿ç”¨MCPå·¥å…·ï¼Œæ”¯æŒæµå¼è¾“å‡º
"""

import asyncio
import json
import logging
import re
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime
import sys
import os
from pathlib import Path

# æ·»åŠ utilsè·¯å¾„åˆ°sys.path
utils_path = Path(__file__).parent.parent / "utils"
if str(utils_path) not in sys.path:
    sys.path.append(str(utils_path))

from myLLM import chat_with_llm
from persona_prompts import get_persona_prompt
from pydantic import BaseModel

from .tool_service import ToolService
from .mcp_client_service import MCPClientService, LogType
from utils.persona_prompts import persona_manager

class ChatMessage(BaseModel):
    """èŠå¤©æ¶ˆæ¯æ¨¡å‹"""
    role: str
    content: str

class StreamChunk(BaseModel):
    """æµå¼è¾“å‡ºæ•°æ®å—"""
    type: str  # message, tool_call, tool_result, complete, error
    content: str = ""
    data: Optional[Dict[str, Any]] = None
    timestamp: str = ""

class LLMService:
    """ç®€åŒ–çš„LLMæœåŠ¡ç±»"""
    
    def __init__(self, tool_service: ToolService, api_key: str = None, model: str = "gpt-4o-mini", llm_type: str = "openai"):
        """
        åˆå§‹åŒ–LLMæœåŠ¡
        
        Args:
            tool_service: å·¥å…·æœåŠ¡å®ä¾‹
            api_key: APIå¯†é’¥
            model: æ¨¡å‹åç§°
            llm_type: LLMç±»å‹
        """
        self.tool_service = tool_service
        self.api_key = api_key
        self.model = model
        self.llm_type = llm_type
        self.logger = logging.getLogger(__name__)
        
        # åŸºç¡€ç³»ç»Ÿæç¤ºè¯ï¼Œå·¥å…·ä¿¡æ¯å°†åœ¨è¿è¡Œæ—¶åŠ¨æ€æ·»åŠ 
        self.base_system_prompt = """
ä½œä¸ºä¸“å®¶ï¼Œä½ å¯ä»¥ï¼š
- æŸ¥è¯¢å’Œåˆ†ææ•°æ®åº“ä¸­çš„æ•°æ®
- æ‰§è¡Œæ•°æ®åº“çš„å¢åˆ æ”¹æŸ¥æ“ä½œ
- æä¾›æ•°æ®ç»“æ„å’Œæ¶æ„ä¿¡æ¯
- ååŠ©æ•°æ®åˆ†æå’Œæ´å¯Ÿç”Ÿæˆ
- å¤„ç†ç”¨æˆ·çš„å¼€å‘éœ€æ±‚å’ŒæŠ€æœ¯é—®é¢˜

**å·¥å…·è°ƒç”¨å…³é”®è§„åˆ™ï¼ˆå¿…é¡»ä¸¥æ ¼éµå¾ªï¼‰ï¼š**
1. å½“éœ€è¦æ•°æ®åº“æ“ä½œæ—¶ï¼Œç«‹å³è°ƒç”¨ç›¸åº”å·¥å…·ï¼Œä¸è¦æ‰¿è¯ºç¨åè°ƒç”¨
2. å·¥å…·è°ƒç”¨å¿…é¡»ä¸¥æ ¼æŒ‰ç…§JSONæ ¼å¼ï¼š{"tool_call": {"name": "å·¥å…·å", "args": {...}}}
3. å·¥å…·è°ƒç”¨å¿…é¡»æ”¾åœ¨```jsonä»£ç å—ä¸­
4. éªŒè¯å‚æ•°æ ¼å¼åå†å‘é€è°ƒç”¨ï¼Œä¸ç¡®å®šæ—¶è¯¢é—®æ¾„æ¸…è€ŒéçŒœæµ‹
5. æ¯æ¬¡åªè°ƒç”¨ä¸€ä¸ªå·¥å…·
6. å¦‚æœä»»åŠ¡éœ€è¦å¤šä¸ªæ­¥éª¤ï¼ŒæŒç»­ä½¿ç”¨å·¥å…·ç›´åˆ°å®Œæˆï¼Œä¸è¦åœ¨ç¬¬ä¸€æ¬¡å¤±è´¥æ—¶åœæ­¢

**å·¥å…·ä½¿ç”¨è¾¹ç•Œï¼š**
ä½¿ç”¨å·¥å…·çš„æƒ…å†µï¼š
- ç”¨æˆ·è¯¢é—®æ•°æ®åº“è¡¨ç»“æ„ã€æ•°æ®å†…å®¹
- ç”¨æˆ·è¦æ±‚æŸ¥è¯¢ã€æ’å…¥ã€æ›´æ–°ã€åˆ é™¤æ•°æ®
- ç”¨æˆ·éœ€è¦æ•°æ®åˆ†ææˆ–ç»Ÿè®¡ä¿¡æ¯
- ç”¨æˆ·è¦æ±‚æ‰§è¡Œä»»ä½•SQLæ“ä½œ
- ç”¨æˆ·è¯¢é—®å…·ä½“çš„æ•°æ®åº“æ¶æ„ä¿¡æ¯

ä¸ä½¿ç”¨å·¥å…·çš„æƒ…å†µï¼š
- ç”¨æˆ·è¯¢é—®ä¸€èˆ¬æ€§çš„ç¼–ç¨‹æ¦‚å¿µæˆ–ç†è®ºé—®é¢˜
- ç”¨æˆ·è¦æ±‚ä»£ç ç¤ºä¾‹ï¼ˆéæ•°æ®åº“æ“ä½œï¼‰
- ç”¨æˆ·å¯»æ±‚æŠ€æœ¯å»ºè®®æˆ–æœ€ä½³å®è·µ
- ç”¨æˆ·è¿›è¡Œç®€å•çš„é—®å€™æˆ–é—²èŠ

**æ•°æ®åº“æ“ä½œæ‰§è¡Œé¡ºåºï¼š**
1. æŸ¥çœ‹è¡¨ç»“æ„å‰ï¼Œå…ˆåˆ—å‡ºæ‰€æœ‰è¡¨
2. æ’å…¥æ•°æ®å‰ï¼Œç¡®è®¤è¡¨ç»“æ„å’Œå­—æ®µè¦æ±‚
3. å¤æ‚æŸ¥è¯¢å‰ï¼Œäº†è§£ç›¸å…³è¡¨çš„å…³ç³»
4. ä¿®æ”¹æ•°æ®å‰ï¼Œå…ˆæŸ¥è¯¢ç¡®è®¤ç°æœ‰æ•°æ®

**é‡è¦æ ¼å¼è§„èŒƒï¼š**
- sqlite_insert_dataå·¥å…·çš„dataå‚æ•°å¿…é¡»æ˜¯JSONå­—ç¬¦ä¸²æ ¼å¼ï¼Œå¦‚ï¼š"{\"name\": \"å¼ ä¸‰\", \"age\": 25}"
- UPDATE/DELETEæ“ä½œä½¿ç”¨sqlite_queryå·¥å…·
- æ‰€æœ‰SELECTæŸ¥è¯¢ä½¿ç”¨sqlite_queryå·¥å…·
- è¡¨ç»“æ„æŸ¥è¯¢ä½¿ç”¨sqlite_describe_tableå·¥å…·

**å·¥å…·è°ƒç”¨ç¤ºä¾‹ï¼š**
```json
{
  "tool_call": {
    "name": "sqlite_list_tables",
    "args": {}
  }
}
```

```json
{
  "tool_call": {
    "name": "sqlite_insert_data",
    "args": {
      "table_name": "accounts",
      "data": "{\"name\": \"æ–°ç”¨æˆ·\", \"status\": \"active\"}"
    }
  }
}
```

**ç¦æ­¢è¡Œä¸ºï¼š**
- ä¸è¦è¯´"æˆ‘å°†ä¸ºæ‚¨è°ƒç”¨å·¥å…·"æˆ–"ç¨åæˆ‘ä¼šæŸ¥è¯¢æ•°æ®åº“"ï¼Œéœ€è¦å·¥å…·æ—¶ç«‹å³è°ƒç”¨
- ä¸è¦çŒœæµ‹å‚æ•°å€¼ï¼Œä¸ç¡®å®šæ—¶è¯·è¦æ±‚ç”¨æˆ·æ¾„æ¸…
- ä¸è¦åœ¨å•æ¬¡å“åº”ä¸­æ‰¿è¯ºå¤šä¸ªå·¥å…·è°ƒç”¨ï¼ŒæŒ‰éœ€é€ä¸ªæ‰§è¡Œ
- ä¸è¦ä½¿ç”¨é™¤äº†æŒ‡å®šJSONæ ¼å¼å¤–çš„ä»»ä½•å·¥å…·è°ƒç”¨æ ¼å¼"""
        
    async def process_message_stream(self, user_input: str, 
                                   conversation_history: Optional[List[Dict[str, Any]]] = None, 
                                   model: str = None,
                                   attached_data: Optional[List[Dict[str, Any]]] = None) -> AsyncGenerator[StreamChunk, None]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼Œæ”¯æŒå·¥å…·è°ƒç”¨å’ŒåŠ¨æ€agentåˆ‡æ¢
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            conversation_history: å¯¹è¯å†å²
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
            attached_data: é™„åŠ æ•°æ®ï¼ŒåŒ…å«persona_contextç­‰ä¿¡æ¯
            
        Yields:
            StreamChunk: æµå¼è¾“å‡ºæ•°æ®å—
        """
        try:
            # è·å–å¯ç”¨å·¥å…·å¹¶æ„å»ºå®Œæ•´çš„ç³»ç»Ÿæç¤ºè¯
            available_tools = await self.tool_service.get_tools_for_llm()
            tools_text = self._format_tools_for_llm(available_tools)
            
            # æ£€æŸ¥æ˜¯å¦æœ‰persona_contextï¼Œç”¨äºåŠ¨æ€åˆ‡æ¢agent
            agent_prompt = self.base_system_prompt
            enhanced_user_input = user_input
            
            if attached_data:
                # å¤„ç†agentåˆ‡æ¢ - ä¼˜å…ˆæŸ¥æ‰¾åŒ…å«agentå­—æ®µçš„persona_context
                for data_item in attached_data:
                    if (data_item.get("type") == "persona_context" and 
                        data_item.get("data") and 
                        data_item.get("data", {}).get("agent")):
                        persona_data = data_item["data"]
                        # ä½¿ç”¨persona_managerè·å–å¯¹åº”çš„agentæç¤ºè¯
                        agent_prompt = persona_manager.get_persona_by_context(persona_data)
                        print(f"ğŸ¤– æ£€æµ‹åˆ°agentåˆ‡æ¢: {persona_data.get('agent', 'æœªçŸ¥')}")
                        break
                
                # å¤„ç†é™„åŠ çš„æ•°æ®å†…å®¹ï¼Œå°†å…¶æ·»åŠ åˆ°ç”¨æˆ·è¾“å…¥ä¸­
                context_data_list = []
                for data_item in attached_data:
                    data_type = data_item.get("type", "")
                    data_content = data_item.get("data", {})
                    data_name = data_item.get("name", "")
                    
                    # è·³è¿‡ç”¨äºagenté€‰æ‹©çš„persona_contextæ•°æ®
                    if (data_type == "persona_context" and 
                        data_content.get("agent") is not None):
                        continue
                    
                    # å¤„ç†persona_contextæ•°æ®
                    if data_type == "persona_context" and data_content:
                        context_data_list.append({
                            "type": "è´¦å·äººè®¾ä¿¡æ¯",
                            "name": data_name,
                            "content": data_content
                        })
                        print(f"ğŸ“‹ å¤„ç†å¼•ç”¨æ•°æ®: ç±»å‹=persona_context, åç§°={data_name}")
                    
                    # å¤„ç†product_contextæ•°æ®  
                    elif data_type == "product_context" and data_content:
                        context_data_list.append({
                            "type": "äº§å“ä¿¡æ¯",
                            "name": data_name,
                            "content": data_content
                        })
                        print(f"ğŸ“‹ å¤„ç†å¼•ç”¨æ•°æ®: ç±»å‹=product_context, åç§°={data_name}")
                    
                    # å¤„ç†å…¶ä»–ç±»å‹çš„æ•°æ®
                    elif data_type in ["xiaohongshu_note", "xiaohongshu_search"] and data_content:
                        context_data_list.append({
                            "type": "å°çº¢ä¹¦æ•°æ®",
                            "name": data_name,
                            "content": data_content
                        })
                        print(f"ğŸ“‹ å¤„ç†å¼•ç”¨æ•°æ®: ç±»å‹={data_type}, åç§°={data_name}")
                
                # å¦‚æœæœ‰æ•°æ®å†…å®¹ï¼Œæ·»åŠ åˆ°ç”¨æˆ·è¾“å…¥ä¸­
                if context_data_list:
                    context_text = "\n\nğŸ“ ä»¥ä¸‹æ˜¯æˆ‘æä¾›çš„ç›¸å…³æ•°æ®ï¼š\n"
                    for i, context_item in enumerate(context_data_list, 1):
                        context_text += f"\n{i}. ã€{context_item['type']}ã€‘{context_item['name']}\n"
                        context_text += f"   æ•°æ®å†…å®¹ï¼š{str(context_item['content'])}\n"
                    
                    enhanced_user_input = user_input + context_text
                    print(f"âœ… å¢å¼ºè¾“å…¥é•¿åº¦: {len(enhanced_user_input)}")
                    print(f"ğŸ“ å‘ç°é™„åŠ æ•°æ®: {len(context_data_list)} é¡¹")
                    for i, item in enumerate(context_data_list, 1):
                        print(f"   {i}. ã€{item['type']}ã€‘{item['name']}")
            
            system_prompt = f"""
                            {agent_prompt}
                            {self.base_system_prompt}
                            {tools_text}
                            """

            # æ„å»ºå¯¹è¯å†å²
            messages = [{"role": "system", "content": system_prompt}]
            print(f"ğŸ” æ„å»ºçš„ç³»ç»Ÿæç¤ºè¯: {system_prompt[:]}...")
            
            # æ·»åŠ å†å²å¯¹è¯
            if conversation_history:
                for msg in conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
                    if msg.get("role") in ["user", "assistant"]:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥ï¼ˆä½¿ç”¨å¢å¼ºåçš„è¾“å…¥ï¼‰
            messages.append({"role": "user", "content": enhanced_user_input})
            
            # å‘é€å¼€å§‹å¤„ç†æ¶ˆæ¯
            yield StreamChunk(
                type="start",
                content="å¼€å§‹å¤„ç†æ‚¨çš„é—®é¢˜...",
                timestamp=datetime.now().isoformat()
            )
            
            # å¼€å§‹LLMå¯¹è¯å¾ªç¯
            max_iterations = 5  # æœ€å¤§å·¥å…·è°ƒç”¨è¿­ä»£æ¬¡æ•°
            iteration = 0
            
            while iteration < max_iterations:
                iteration += 1
                
                # è°ƒç”¨LLM
                yield StreamChunk(
                    type="llm_thinking",
                    content=f"LLMæ­£åœ¨æ€è€ƒ... (ç¬¬{iteration}è½®)",
                    timestamp=datetime.now().isoformat()
                )
                
                # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹ï¼ˆå¦‚æœæä¾›äº†çš„è¯ï¼‰
                current_model = model if model else self.model
                llm_response = await self._call_llm(messages, current_model)
                
                # æ£€æŸ¥æ˜¯å¦åŒ…å«å·¥å…·è°ƒç”¨
                tool_call = self._extract_tool_call(llm_response)
                
                if tool_call:
                    # æå–å·¥å…·è°ƒç”¨å‰çš„æ–‡æœ¬å†…å®¹
                    tool_call_text = ""
                    json_pattern = r'```json.*?```'
                    text_before_tool = re.split(json_pattern, llm_response, flags=re.DOTALL | re.IGNORECASE)
                    
                    if text_before_tool and text_before_tool[0].strip():
                        # æœ‰å·¥å…·è°ƒç”¨å‰çš„è¯´æ˜æ–‡å­—ï¼Œå…ˆæ˜¾ç¤ºè¿™éƒ¨åˆ†
                        explanation_text = text_before_tool[0].strip()
                        yield StreamChunk(
                            type="ai_message",
                            content=explanation_text,
                            timestamp=datetime.now().isoformat()
                        )
                    
                    # æ˜¾ç¤ºå·¥å…·è°ƒç”¨ä¿¡æ¯
                    yield StreamChunk(
                        type="tool_call",
                        content=f"è°ƒç”¨å·¥å…·: {tool_call['name']}",
                        data=tool_call,
                        timestamp=datetime.now().isoformat()
                    )
                    
                    # æ‰§è¡Œå·¥å…·è°ƒç”¨
                    try:
                        # ä¿®å¤ç‰¹å®šå·¥å…·çš„å‚æ•°æ ¼å¼
                        fixed_args = self._fix_tool_args(tool_call["name"], tool_call["args"])
                        
                        tool_result = await self.tool_service.call_tool(
                            tool_call["name"], 
                            fixed_args
                        )
                        
                        # å¤„ç†å·¥å…·ç»“æœ
                        result_content = self._format_tool_result(tool_result)
                        
                        yield StreamChunk(
                            type="tool_result",
                            content=f"å·¥å…· {tool_call['name']} æ‰§è¡Œå®Œæˆ",
                            data={"result": result_content, "success": True},
                            timestamp=datetime.now().isoformat()
                        )
                        
                        # å°†å·¥å…·è°ƒç”¨å’Œç»“æœæ·»åŠ åˆ°å¯¹è¯å†å²
                        messages.append({
                            "role": "assistant", 
                            "content": f"æˆ‘è°ƒç”¨äº†å·¥å…· {tool_call['name']}ï¼Œå‚æ•°: {json.dumps(tool_call['args'], ensure_ascii=False)}"
                        })
                        messages.append({
                            "role": "user", 
                            "content": f"å·¥å…·æ‰§è¡Œç»“æœï¼š{result_content}"
                        })
                        
                        # ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯ï¼Œè®©LLMåŸºäºå·¥å…·ç»“æœç»§ç»­å¤„ç†
                        continue
                        
                    except Exception as e:
                        # å·¥å…·è°ƒç”¨å¤±è´¥
                        yield StreamChunk(
                            type="tool_error",
                            content=f"å·¥å…· {tool_call['name']} æ‰§è¡Œå¤±è´¥: {str(e)}",
                            data={"error": str(e)},
                            timestamp=datetime.now().isoformat()
                        )
                        
                        # å‘Šè¯‰LLMå·¥å…·è°ƒç”¨å¤±è´¥
                        messages.append({
                            "role": "assistant", 
                            "content": f"æˆ‘å°è¯•è°ƒç”¨å·¥å…· {tool_call['name']}ï¼Œä½†æ‰§è¡Œå¤±è´¥äº†ã€‚"
                        })
                        messages.append({
                            "role": "user", 
                            "content": f"å·¥å…·è°ƒç”¨å¤±è´¥ï¼š{str(e)}ã€‚è¯·ä¸è¦å†ä½¿ç”¨è¿™ä¸ªå·¥å…·ï¼Œç›´æ¥å›ç­”é—®é¢˜ã€‚"
                        })
                        
                        # ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯
                        continue
                        
                else:
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›ç­”æ¡ˆ
                    yield StreamChunk(
                        type="final_answer",
                        content=llm_response,
                        timestamp=datetime.now().isoformat()
                    )
                    yield StreamChunk(
                        type="complete",
                        content="å¯¹è¯å®Œæˆ",
                        timestamp=datetime.now().isoformat()
                    )
                    return
            
            # å¦‚æœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œå¼ºåˆ¶ç»“æŸ
            yield StreamChunk(
                type="max_iterations",
                content="å·²è¾¾åˆ°æœ€å¤§å·¥å…·è°ƒç”¨æ¬¡æ•°ï¼Œè¯·å‘Šè¯‰æˆ‘æ‚¨éœ€è¦ä»€ä¹ˆå¸®åŠ©ã€‚",
                timestamp=datetime.now().isoformat()
            )
            yield StreamChunk(
                type="complete",
                content="å¯¹è¯å®Œæˆ",
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as error:
            self.logger.error(f"æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {error}")
            yield StreamChunk(
                type="error",
                content=f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {error}",
                data={"error": str(error)},
                timestamp=datetime.now().isoformat()
            )
    
    def _format_tools_for_llm(self, tools: List[Dict[str, Any]]) -> str:
        """æ ¼å¼åŒ–å·¥å…·ä¿¡æ¯ç»™LLMï¼Œé‡è¦ä¿¡æ¯å‰ç½®"""
        if not tools:
            return "å½“å‰æ²¡æœ‰å¯ç”¨çš„å·¥å…·ã€‚"
        
        tools_text = f"å¯ç”¨å·¥å…·æ¸…å• ({len(tools)}ä¸ª):\n\n"
        
        # æŒ‰å·¥å…·é‡è¦æ€§æ’åºï¼Œæ•°æ®åº“ç›¸å…³å·¥å…·ä¼˜å…ˆ
        priority_order = {
            'sqlite_list_tables': 1,
            'sqlite_describe_table': 2, 
            'sqlite_query': 3,
            'sqlite_insert_data': 4,
            'sqlite_get_schema': 5
        }
        
        sorted_tools = sorted(tools, key=lambda x: priority_order.get(x['name'], 999))
        
        for i, tool in enumerate(sorted_tools, 1):
            tools_text += f"{i}. **{tool['name']}**\n"
            tools_text += f"   åŠŸèƒ½: {tool['description']}\n"
            
            # æ·»åŠ å‚æ•°ä¿¡æ¯ï¼ˆå¦‚æœæœ‰ï¼‰
            if tool.get('parameters') and tool['parameters'].get('properties'):
                props = tool['parameters']['properties']
                required = tool['parameters'].get('required', [])
                
                tools_text += "   å‚æ•°:\n"
                for param_name, param_info in props.items():
                    param_type = param_info.get('type', 'unknown')
                    is_required = " (å¿…éœ€)" if param_name in required else " (å¯é€‰)"
                    tools_text += f"     - {param_name} ({param_type}){is_required}\n"
            else:
                tools_text += "   å‚æ•°: æ— \n"
            
            tools_text += "\n"
        
        return tools_text
    
    def _fix_tool_args(self, tool_name: str, args: Dict[str, Any]) -> Dict[str, Any]:
        """ä¿®å¤å·¥å…·å‚æ•°æ ¼å¼"""
        fixed_args = args.copy()
        
        # ä¿®å¤sqlite_insert_dataçš„dataå‚æ•°
        if tool_name == "sqlite_insert_data" and "data" in fixed_args:
            data_value = fixed_args["data"]
            # å¦‚æœdataæ˜¯å­—å…¸ï¼Œè½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
            if isinstance(data_value, dict):
                fixed_args["data"] = json.dumps(data_value, ensure_ascii=False)
                print(f"ğŸ”§ ä¿®å¤sqlite_insert_dataå‚æ•°: {fixed_args}")
            elif not isinstance(data_value, str):
                # å¦‚æœä¸æ˜¯å­—ç¬¦ä¸²ä¹Ÿä¸æ˜¯å­—å…¸ï¼Œå°è¯•è½¬æ¢ä¸ºJSONå­—ç¬¦ä¸²
                fixed_args["data"] = json.dumps(data_value, ensure_ascii=False)
                print(f"ğŸ”§ ä¿®å¤sqlite_insert_dataå‚æ•°: {fixed_args}")
        
        return fixed_args
    
    def _extract_tool_call(self, text: str) -> Optional[Dict[str, Any]]:
        """ä»LLMå“åº”ä¸­æå–å·¥å…·è°ƒç”¨ï¼Œé˜²èŒƒå¹»è§‰"""
        try:
            print(f"ğŸ” å°è¯•ä»ä»¥ä¸‹æ–‡æœ¬ä¸­æå–å·¥å…·è°ƒç”¨:\n{text}")
            
            # æ£€æµ‹å¹»è§‰æ¨¡å¼ï¼šæ‰¿è¯ºæœªæ¥è°ƒç”¨å·¥å…·çš„è¡¨è¿°
            hallucination_patterns = [
                r'æˆ‘å°†.*?è°ƒç”¨',
                r'ç¨å.*?å·¥å…·',
                r'æ¥ä¸‹æ¥.*?ä½¿ç”¨',
                r'åç»­.*?æ‰§è¡Œ',
                r'ä¸‹ä¸€æ­¥.*?è°ƒç”¨'
            ]
            
            for pattern in hallucination_patterns:
                if re.search(pattern, text):
                    print(f"ğŸš¨ æ£€æµ‹åˆ°å¯èƒ½çš„å·¥å…·è°ƒç”¨å¹»è§‰æ¨¡å¼: {pattern}")
                    # å¦‚æœæ£€æµ‹åˆ°å¹»è§‰æ¨¡å¼ä½†æ²¡æœ‰å®é™…å·¥å…·è°ƒç”¨ï¼Œè¿”å›None
                    if '```json' not in text.lower():
                        print("âŒ å‘ç°å¹»è§‰ï¼šæ‰¿è¯ºè°ƒç”¨å·¥å…·ä½†æœªå®é™…æ‰§è¡Œ")
                        return None
            
            # æ–¹æ³•1: æŸ¥æ‰¾ ```json ä»£ç å—ï¼Œå¹¶ä¿®å¤åŒå¤§æ‹¬å·é—®é¢˜
            json_pattern = r'```json\s*\n?(.*?)\n?```'
            matches = re.findall(json_pattern, text, re.DOTALL | re.IGNORECASE)
            
            for match in matches:
                try:
                    # ä¿®å¤åŒå¤§æ‹¬å·é—®é¢˜
                    cleaned_match = match.strip()
                    # å°†åŒå¤§æ‹¬å·æ›¿æ¢ä¸ºå•å¤§æ‹¬å·
                    cleaned_match = cleaned_match.replace('{{', '{').replace('}}', '}')
                    print(f"ğŸ”§ æ¸…ç†åçš„JSON: {cleaned_match}")
                    
                    parsed = json.loads(cleaned_match)
                    if "tool_call" in parsed:
                        tool_call = parsed["tool_call"]
                        if "name" in tool_call and "args" in tool_call:
                            print(f"âœ… æ–¹æ³•1æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                            return tool_call
                except json.JSONDecodeError as e:
                    print(f"âŒ æ–¹æ³•1 JSONè§£æå¤±è´¥: {e}")
                    continue
            
            # æ–¹æ³•2: ç›´æ¥æŸ¥æ‰¾JSONå¯¹è±¡ï¼Œå¹¶ä¿®å¤åŒå¤§æ‹¬å·
            json_pattern2 = r'\{[^{}]*"tool_call"[^{}]*\}'
            matches2 = re.findall(json_pattern2, text, re.DOTALL)
            
            for match in matches2:
                try:
                    # ä¿®å¤åŒå¤§æ‹¬å·é—®é¢˜
                    cleaned_match = match.replace('{{', '{').replace('}}', '}')
                    print(f"ğŸ”§ æ–¹æ³•2æ¸…ç†åçš„JSON: {cleaned_match}")
                    
                    parsed = json.loads(cleaned_match)
                    if "tool_call" in parsed:
                        tool_call = parsed["tool_call"]
                        if "name" in tool_call and "args" in tool_call:
                            print(f"âœ… æ–¹æ³•2æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                            return tool_call
                except json.JSONDecodeError as e:
                    print(f"âŒ æ–¹æ³•2 JSONè§£æå¤±è´¥: {e}")
                    continue
            
            # æ–¹æ³•3: æŸ¥æ‰¾æ›´å¤æ‚çš„JSONç»“æ„ï¼Œæ”¯æŒåŒå¤§æ‹¬å·
            json_pattern3 = r'\{\{.*?"tool_call".*?\}\}|\{.*?"tool_call".*?\}'
            matches3 = re.findall(json_pattern3, text, re.DOTALL)
            
            for match in matches3:
                try:
                    # ä¿®å¤åŒå¤§æ‹¬å·é—®é¢˜
                    cleaned_match = match.strip().replace('{{', '{').replace('}}', '}')
                    print(f"ğŸ”§ æ–¹æ³•3æ¸…ç†åçš„JSON: {cleaned_match}")
                    
                    parsed = json.loads(cleaned_match)
                    if "tool_call" in parsed:
                        tool_call = parsed["tool_call"]
                        if "name" in tool_call and "args" in tool_call:
                            print(f"âœ… æ–¹æ³•3æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                            return tool_call
                except json.JSONDecodeError as e:
                    print(f"âŒ æ–¹æ³•3 JSONè§£æå¤±è´¥: {e}")
                    continue
            
            # æ–¹æ³•4: æŸ¥æ‰¾æ–‡æœ¬ä¸­æåˆ°çš„å·¥å…·åç§°å’Œå‚æ•°
            tool_name_pattern = r'è°ƒç”¨å·¥å…·\s+(\w+).*?å‚æ•°.*?\{([^}]+)\}'
            tool_matches = re.findall(tool_name_pattern, text, re.DOTALL)
            
            for tool_name, args_str in tool_matches:
                try:
                    # å°è¯•è§£æå‚æ•°
                    args_json = "{" + args_str + "}"
                    args = json.loads(args_json)
                    tool_call = {"name": tool_name, "args": args}
                    print(f"âœ… æ–¹æ³•4æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                    return tool_call
                except json.JSONDecodeError as e:
                    print(f"âŒ æ–¹æ³•4 JSONè§£æå¤±è´¥: {e}")
                    continue
            
            # æ–¹æ³•5: æŸ¥æ‰¾ç‰¹å®šçš„å·¥å…·è°ƒç”¨æ¨¡å¼
            specific_patterns = [
                r'sqlite_describe_table.*?"table_name":\s*"([^"]+)"',
                r'sqlite_list_tables',
                r'sqlite_query.*?"query":\s*"([^"]+)"',
                r'sqlite_insert_data.*?"table_name":\s*"([^"]+)"',
                r'sqlite_get_schema'
            ]
            
            for pattern in specific_patterns:
                matches = re.findall(pattern, text, re.IGNORECASE)
                if matches:
                    if 'describe_table' in pattern:
                        tool_call = {"name": "sqlite_describe_table", "args": {"table_name": matches[0]}}
                        print(f"âœ… æ–¹æ³•5æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                        return tool_call
                    elif 'list_tables' in pattern:
                        tool_call = {"name": "sqlite_list_tables", "args": {}}
                        print(f"âœ… æ–¹æ³•5æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                        return tool_call
                    elif 'query' in pattern:
                        tool_call = {"name": "sqlite_query", "args": {"query": matches[0]}}
                        print(f"âœ… æ–¹æ³•5æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                        return tool_call
                    elif 'get_schema' in pattern:
                        tool_call = {"name": "sqlite_get_schema", "args": {}}
                        print(f"âœ… æ–¹æ³•5æˆåŠŸæå–å·¥å…·è°ƒç”¨: {tool_call}")
                        return tool_call
            
            print("âŒ æ‰€æœ‰æ–¹æ³•éƒ½æœªèƒ½æå–åˆ°å·¥å…·è°ƒç”¨")
            return None
                
        except Exception as e:
            print(f"âŒ æå–å·¥å…·è°ƒç”¨æ—¶å‡ºé”™: {e}")
            return None
    
    def _format_tool_result(self, tool_result: Any) -> str:
        """æ ¼å¼åŒ–å·¥å…·æ‰§è¡Œç»“æœ"""
        try:
            # å¦‚æœæ˜¯MCPToolResultå¯¹è±¡ï¼Œæå–å…¶å†…å®¹
            if hasattr(tool_result, 'content'):
                if isinstance(tool_result.content, list) and len(tool_result.content) > 0:
                    if hasattr(tool_result.content[0], 'text'):
                        return tool_result.content[0].text
                    else:
                        return str(tool_result.content[0])
                elif isinstance(tool_result.content, str):
                    return tool_result.content
                else:
                    return str(tool_result.content)
            
            # å°è¯•JSONåºåˆ—åŒ–
            if isinstance(tool_result, (dict, list)):
                return json.dumps(tool_result, ensure_ascii=False, indent=2)
            
            # ç›´æ¥è½¬æ¢ä¸ºå­—ç¬¦ä¸²
            return str(tool_result)
                
        except Exception as e:
            return f"ç»“æœæ ¼å¼åŒ–å¤±è´¥: {e}"
    
    async def _call_llm(self, messages: List[Dict[str, str]], model: str = None) -> str:
        """
        è°ƒç”¨LLM API
        
        Args:
            messages: æ¶ˆæ¯åˆ—è¡¨
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
            
        Returns:
            LLMå“åº”å†…å®¹
        """
        try:
            # è®°å½•LLMè¯·æ±‚
            # self.tool_service.mcp_client.add_logs(
            #     {"messages": messages, "model": self.model, "llm_type": self.llm_type},
            #     LogType.LLM_REQUEST
            # )
            
            # ä½¿ç”¨æŒ‡å®šçš„æ¨¡å‹æˆ–é»˜è®¤æ¨¡å‹
            current_model = model if model else self.model
            print(f"ğŸ¤– è°ƒç”¨LLM: {self.llm_type}/{current_model}")
            
            # ä½¿ç”¨myLLM.pyä¸­çš„chat_with_llmå‡½æ•°
            response = chat_with_llm(messages, llmType=self.llm_type, model=current_model)
            
            # chat_with_llmè¿”å›çš„æ˜¯JSONå­—ç¬¦ä¸²ï¼Œéœ€è¦è§£æ
            try:
                response_data = json.loads(response)
                content = response_data.get("reply", response)
            except json.JSONDecodeError:
                # å¦‚æœä¸æ˜¯JSONï¼Œç›´æ¥ä½¿ç”¨å“åº”å†…å®¹
                content = response
            
            print(f"âœ… LLMå“åº”é•¿åº¦: {len(content)} å­—ç¬¦")
            
            # è®°å½•LLMå“åº”
            # self.tool_service.mcp_client.add_logs(
            #     {"response": content[:500] + "..." if len(content) > 500 else content},
            #     LogType.LLM_RESPONSE
            # )
            
            return content
            
        except Exception as error:
            error_msg = f"LLMè°ƒç”¨å¤±è´¥: {error}"
            print(f"âŒ {error_msg}")
            # self.tool_service.mcp_client.add_logs(
            #     {"error": str(error)},
            #     LogType.LLM_ERROR
            # )
            raise error
    
    async def simple_chat(self, user_input: str, conversation_history: Optional[List[Dict[str, Any]]] = None, model: str = None) -> str:
        """
        ç®€å•èŠå¤©æ¥å£ï¼ˆéæµå¼ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            conversation_history: å¯¹è¯å†å²
            model: ä½¿ç”¨çš„æ¨¡å‹ï¼ˆå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ¨¡å‹ï¼‰
            
        Returns:
            LLMå›ç­”
        """
        try:
            # æ„å»ºå¯¹è¯å†å²
            messages = [{"role": "system", "content": self.base_system_prompt}]
            
            # æ·»åŠ å†å²å¯¹è¯
            if conversation_history:
                for msg in conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
                    if msg.get("role") in ["user", "assistant"]:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": user_input})
            
            # è°ƒç”¨LLM
            response = await self._call_llm(messages, model)
            return response
            
        except Exception as error:
            self.logger.error(f"ç®€å•èŠå¤©å¤±è´¥: {error}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯: {error}"
    
    async def simple_chat_with_persona(self, user_input: str, 
                                     conversation_history: Optional[List[Dict[str, Any]]] = None, 
                                     model: str = None,
                                     persona_prompt: str = "") -> str:
        """
        å¸¦äººè®¾çš„ç®€å•èŠå¤©æ¥å£ï¼ˆéæµå¼ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            conversation_history: å¯¹è¯å†å²
            model: ä½¿ç”¨çš„æ¨¡å‹
            persona_prompt: äººè®¾ç³»ç»Ÿæç¤ºè¯
            
        Returns:
            LLMå›ç­”
        """
        try:
            # æ„å»ºå¯¹è¯å†å²ï¼Œä½¿ç”¨äººè®¾æç¤ºè¯ä½œä¸ºç³»ç»Ÿæ¶ˆæ¯
            messages = []
            
            # ä½¿ç”¨äººè®¾æç¤ºè¯æˆ–é»˜è®¤ç³»ç»Ÿæç¤ºè¯
            system_prompt = persona_prompt if persona_prompt else self.base_system_prompt
            messages.append({"role": "system", "content": system_prompt})
            
            # æ·»åŠ å†å²å¯¹è¯
            if conversation_history:
                for msg in conversation_history[-5:]:  # åªä¿ç•™æœ€è¿‘5è½®å¯¹è¯
                    if msg.get("role") in ["user", "assistant"]:
                        messages.append({
                            "role": msg["role"],
                            "content": msg["content"]
                        })
            
            # æ·»åŠ å½“å‰ç”¨æˆ·è¾“å…¥
            messages.append({"role": "user", "content": user_input})
            
            print(f"ğŸ­ ä½¿ç”¨äººè®¾èŠå¤©ï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
            
            # è°ƒç”¨LLM
            response = await self._call_llm(messages, model)
            print(f"ğŸ­ äººè®¾èŠå¤©å“åº”: {response}ï¼Œ messages: {messages}")

            return response
            
        except Exception as error:
            self.logger.error(f"äººè®¾èŠå¤©å¤±è´¥: {error}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯: {error}" 