"""
ç®€åŒ–çš„èŠå¤©æœåŠ¡
è´Ÿè´£å¤„ç†èŠå¤©æµç¨‹ï¼Œè‡ªåŠ¨è¿æ¥MCPï¼Œå¹¶æä¾›æµå¼è¾“å‡º
"""

import asyncio
import json
import logging
from typing import Dict, List, Any, Optional, AsyncGenerator
from datetime import datetime
from pathlib import Path

from .llm_service import LLMService, StreamChunk
from .tool_service import ToolService
from .mcp_client_service import mcp_client_service  # ä½¿ç”¨å…¨å±€å®ä¾‹
from .mcp_server_manager import mcp_server_manager
from .multi_mcp_client_service import multi_mcp_client_service  # å¤šæœåŠ¡å™¨MCPå®¢æˆ·ç«¯

class ChatService:
    """ç®€åŒ–çš„èŠå¤©æœåŠ¡ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–èŠå¤©æœåŠ¡"""
        self.logger = logging.getLogger(__name__)
        
        # ä½¿ç”¨å¤šæœåŠ¡å™¨MCPå®¢æˆ·ç«¯å®ä¾‹
        self.multi_mcp_client = multi_mcp_client_service
        
        # ä¿ç•™å•æœåŠ¡å™¨MCPå®¢æˆ·ç«¯ä½œä¸ºå¤‡ç”¨
        self.mcp_client = mcp_client_service
        
        # åˆå§‹åŒ–å·¥å…·æœåŠ¡ï¼ˆä¼˜å…ˆä½¿ç”¨å¤šæœåŠ¡å™¨å®¢æˆ·ç«¯ï¼‰
        self.tool_service = ToolService(self.multi_mcp_client)
        
        # åˆå§‹åŒ–LLMæœåŠ¡
        self.llm_service = LLMService(self.tool_service)
        
        # MCPè¿æ¥çŠ¶æ€æ ‡å¿—
        self._mcp_initialized = False
        
        print("ğŸ‰ èŠå¤©æœåŠ¡åˆå§‹åŒ–å®Œæˆï¼ˆæ”¯æŒå¤šMCPæœåŠ¡å™¨ï¼‰")
    
    async def _ensure_mcp_connected(self):
        """ç¡®ä¿MCPå·²è¿æ¥ï¼ˆå»¶è¿Ÿåˆå§‹åŒ–ï¼‰"""
        if not self._mcp_initialized:
            await self._auto_connect_mcp()
            self._mcp_initialized = True
    
    async def _auto_connect_mcp(self):
        """è‡ªåŠ¨è¿æ¥MCPæœåŠ¡å™¨ï¼ˆä¼˜å…ˆä½¿ç”¨å¤šæœåŠ¡å™¨è¿æ¥ï¼‰"""
        try:
            print("ğŸ”Œ å¼€å§‹è‡ªåŠ¨è¿æ¥æ‰€æœ‰MCPæœåŠ¡å™¨...")
            
            # é¦–å…ˆå°è¯•è¿æ¥åˆ°æ‰€æœ‰æœåŠ¡å™¨ï¼ˆSQL + å°çº¢ä¹¦ï¼‰
            success = await self.multi_mcp_client.connect_to_all_servers()
            
            if success:
                print("âœ… å¤šæœåŠ¡å™¨MCPè¿æ¥æˆåŠŸ")
                return True
            else:
                print("âš ï¸ å¤šæœåŠ¡å™¨MCPè¿æ¥å¤±è´¥ï¼Œå°è¯•å•æœåŠ¡å™¨æ¨¡å¼...")
                
                # å¦‚æœå¤šæœåŠ¡å™¨è¿æ¥å¤±è´¥ï¼Œå›é€€åˆ°å•æœåŠ¡å™¨æ¨¡å¼
                fallback_success = await mcp_server_manager.auto_connect_best_server()
                
                if fallback_success:
                    print("âœ… å•æœåŠ¡å™¨MCPè¿æ¥æˆåŠŸï¼ˆå›é€€æ¨¡å¼ï¼‰")
                    # åˆ‡æ¢å·¥å…·æœåŠ¡åˆ°å•æœåŠ¡å™¨å®¢æˆ·ç«¯
                    self.tool_service = ToolService(self.mcp_client)
                    return True
                else:
                    print("âŒ æ‰€æœ‰MCPè¿æ¥æ–¹å¼éƒ½å¤±è´¥")
                    return False
            
        except Exception as e:
            print(f"âŒ è‡ªåŠ¨è¿æ¥MCPæœåŠ¡å™¨å¤±è´¥: {e}")
            return False
    
    async def process_message_stream(self, user_input: str, user_id: str = "default", 
                                   model: str = "gpt-4o-mini",
                                   conversation_history: Optional[List[Dict[str, Any]]] = None,
                                   attached_data: Optional[List[Dict[str, Any]]] = None) -> AsyncGenerator[Dict[str, Any], None]:
        """
        æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            user_id: ç”¨æˆ·ID
            model: ä½¿ç”¨çš„AIæ¨¡å‹
            conversation_history: å¯¹è¯å†å²
            attached_data: é™„åŠ çš„å¼•ç”¨æ•°æ®
            
        Yields:
            æµå¼å“åº”æ•°æ®
        """
        try:
            print(f"ğŸ“¨ æ”¶åˆ°ç”¨æˆ·æ¶ˆæ¯: {user_input[:50]}...")
            
            # è®°å½•é™„åŠ æ•°æ®ä¿¡æ¯
            if attached_data and len(attached_data) > 0:
                print(f"ğŸ“ æ£€æµ‹åˆ°é™„åŠ æ•°æ®: {len(attached_data)} é¡¹")
                for i, data in enumerate(attached_data, 1):
                    data_type = data.get('type', 'unknown')
                    data_name = data.get('data', {}).get('name', 'æœªçŸ¥')
                    print(f"   {i}. ã€{data_type}ã€‘{data_name}")
            
            # ç¡®ä¿MCPå·²è¿æ¥
            await self._ensure_mcp_connected()
            
            # å¼€å§‹æµå¼å¤„ç†
            async for chunk in self.llm_service.process_message_stream(user_input, conversation_history, model):
                # è½¬æ¢ä¸ºAPIå“åº”æ ¼å¼
                yield {
                    "type": chunk.type,
                    "content": chunk.content,
                    "data": chunk.data,
                    "timestamp": chunk.timestamp
                }
                
        except Exception as error:
            self.logger.error(f"æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {error}")
            yield {
                "type": "error",
                "content": f"å¤„ç†æ¶ˆæ¯æ—¶å‘ç”Ÿé”™è¯¯: {error}",
                "data": {"error": str(error)},
                "timestamp": datetime.now().isoformat()
            }
    
    async def simple_chat(self, user_input: str, user_id: str = "default", 
                         model: str = "gpt-4o-mini",
                         conversation_history: Optional[List[Dict[str, Any]]] = None) -> str:
        """
        ç®€å•èŠå¤©æ¥å£ï¼ˆéæµå¼ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            user_id: ç”¨æˆ·ID
            model: ä½¿ç”¨çš„AIæ¨¡å‹
            conversation_history: å¯¹è¯å†å²
            
        Returns:
            LLMå›ç­”
        """
        try:
            # ç¡®ä¿MCPå·²è¿æ¥
            await self._ensure_mcp_connected()
            
            response = await self.llm_service.simple_chat(user_input, conversation_history, model)
            return response
            
        except Exception as error:
            self.logger.error(f"ç®€å•èŠå¤©å¤±è´¥: {error}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯: {error}"
    
    async def simple_chat_with_persona(self, user_input: str, user_id: str = "default", 
                                     model: str = "gpt-4o-mini",
                                     conversation_history: Optional[List[Dict[str, Any]]] = None,
                                     persona_prompt: str = "") -> str:
        """
        å¸¦äººè®¾çš„ç®€å•èŠå¤©æ¥å£ï¼ˆéæµå¼ï¼‰
        
        Args:
            user_input: ç”¨æˆ·è¾“å…¥
            user_id: ç”¨æˆ·ID
            model: ä½¿ç”¨çš„AIæ¨¡å‹
            conversation_history: å¯¹è¯å†å²
            persona_prompt: äººè®¾ç³»ç»Ÿæç¤ºè¯
            
        Returns:
            LLMå›ç­”
        """
        try:
            # ç¡®ä¿MCPå·²è¿æ¥
            await self._ensure_mcp_connected()
            
            response = await self.llm_service.simple_chat_with_persona(
                user_input, 
                conversation_history, 
                model, 
                persona_prompt
            )
            return response
            
        except Exception as error:
            self.logger.error(f"äººè®¾èŠå¤©å¤±è´¥: {error}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„è¯·æ±‚æ—¶å‘ç”Ÿäº†é”™è¯¯: {error}"
    
    async def get_mcp_status(self) -> Dict[str, Any]:
        """è·å–MCPè¿æ¥çŠ¶æ€"""
        try:
            # ç¡®ä¿MCPå·²è¿æ¥
            await self._ensure_mcp_connected()
            
            # ä¼˜å…ˆæ£€æŸ¥å¤šæœåŠ¡å™¨è¿æ¥çŠ¶æ€
            multi_connected = self.multi_mcp_client.is_connected()
            single_connected = self.mcp_client.is_connected()
            
            is_connected = multi_connected or single_connected
            
            if multi_connected:
                # ä½¿ç”¨å¤šæœåŠ¡å™¨å®¢æˆ·ç«¯çš„å·¥å…·
                tools = await self.multi_mcp_client.get_tools()
                connected_servers = self.multi_mcp_client.get_connected_servers()
                tool_list = [{"name": t.function["name"], "description": t.function["description"]} for t in tools]
                
                return {
                    "connected": True,
                    "tools_count": len(tools),
                    "tools": tool_list,
                    "connected_servers": connected_servers,
                    "connection_type": "multi_server"
                }
            elif single_connected:
                # ä½¿ç”¨å•æœåŠ¡å™¨å®¢æˆ·ç«¯çš„å·¥å…·
                tools = await self.tool_service.get_tools_for_llm()
                tool_list = [{"name": t["name"], "description": t["description"]} for t in tools]
                
                return {
                    "connected": True,
                    "tools_count": len(tools),
                    "tools": tool_list,
                    "connected_servers": ["single_server"],
                    "connection_type": "single_server"
                }
            else:
                return {
                    "connected": False,
                    "tools_count": 0,
                    "tools": [],
                    "connected_servers": [],
                    "connection_type": "none"
                }
            
        except Exception as e:
            self.logger.error(f"è·å–MCPçŠ¶æ€å¤±è´¥: {e}")
            return {
                "connected": False,
                "tools_count": 0,
                "tools": [],
                "connected_servers": [],
                "error": str(e)
            }
    
    async def reconnect_mcp(self) -> bool:
        """é‡æ–°è¿æ¥MCPæœåŠ¡å™¨"""
        try:
            print("ğŸ”„ é‡æ–°è¿æ¥æ‰€æœ‰MCPæœåŠ¡å™¨...")
            # é‡ç½®åˆå§‹åŒ–æ ‡å¿—ï¼Œå¼ºåˆ¶é‡æ–°è¿æ¥
            self._mcp_initialized = False
            
            # å…³é—­ç°æœ‰è¿æ¥
            if self.multi_mcp_client.is_connected():
                await self.multi_mcp_client.close()
            
            # é‡æ–°è¿æ¥
            await self._ensure_mcp_connected()
            
            # æ£€æŸ¥è¿æ¥çŠ¶æ€
            return self.multi_mcp_client.is_connected() or self.mcp_client.is_connected()
            
        except Exception as e:
            self.logger.error(f"é‡æ–°è¿æ¥MCPå¤±è´¥: {e}")
            return False 